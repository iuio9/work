# Qwen2.5-VL å¤šæ¨¡å‹ååŒè®­ç»ƒæŒ‡å—

## ğŸ“– æ¦‚è¿°

æœ¬ç³»ç»Ÿå®ç°äº†ä» **Qwen2.5-VL 8B** å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ°å¤šç§å°æ¨¡å‹æ¶æ„çš„çŸ¥è¯†è’¸é¦è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒï¼š

### æ”¯æŒçš„å­¦ç”Ÿæ¨¡å‹

| æ¨¡å‹ç±»å‹ | æ¨¡å‹å˜ä½“ | é€‚ç”¨ä»»åŠ¡ | å‚æ•°é‡ |
|---------|---------|---------|--------|
| **ResNet** | resnet18/34/50/101 | å›¾åƒåˆ†ç±» | 11M-44M |
| **Vision Transformer** | vit-tiny/base/large | å›¾åƒåˆ†ç±» | 5M-300M |
| **YOLOv8** | n/s/m/l/x | ç›®æ ‡æ£€æµ‹ | 3M-68M |
| **UNet** | small/medium/large | å›¾åƒåˆ†å‰² | 7M-30M |
| **LSTM** | small/medium/large | åºåˆ—ç‰¹å¾æå–+åˆ†ç±» | 10M-50M |

### æ”¯æŒçš„è’¸é¦ç­–ç•¥

1. **ç‰¹å¾è’¸é¦ (Feature-based)**ï¼šä»Qwen2.5-VLçš„è§†è§‰ç¼–ç å™¨æå–ç‰¹å¾
2. **Logitsè’¸é¦ (Logit-based)**ï¼šç”¨äºåˆ†ç±»ä»»åŠ¡çš„è½¯æ ‡ç­¾è’¸é¦
3. **ä¸­é—´å±‚è’¸é¦ (Layer-wise)**ï¼šé€‚ç”¨äºTransformeræ¶æ„ï¼ˆå¦‚ViTï¼‰
4. **æ··åˆè’¸é¦ (Hybrid)**ï¼šç»“åˆä¸Šè¿°å¤šç§ç­–ç•¥

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  å‰ç«¯é…ç½®é¡µé¢ (Vue3)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ æ•™å¸ˆæ¨¡å‹é€‰æ‹©: Qwen2.5-VL 8B                        â”‚    â”‚
â”‚  â”‚ å­¦ç”Ÿæ¨¡å‹é€‰æ‹©: [ResNet/ViT/YOLO/UNet/LSTM]          â”‚    â”‚
â”‚  â”‚ è’¸é¦ç­–ç•¥: [ç‰¹å¾/Logits/ä¸­é—´å±‚/æ··åˆ]                 â”‚    â”‚
â”‚  â”‚ è®­ç»ƒå‚æ•°: epochs, batch_size, lr, optimizer...    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ JSONé…ç½®
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åç«¯ Spring Boot (Java)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ModelDistillationController                        â”‚    â”‚
â”‚  â”‚  - POST /api/training/create (åˆ›å»ºè®­ç»ƒä»»åŠ¡)        â”‚    â”‚
â”‚  â”‚  - POST /api/training/{id}/start (å¯åŠ¨è®­ç»ƒ)       â”‚    â”‚
â”‚  â”‚  - GET /api/training/{id}/progress (æŸ¥è¯¢è¿›åº¦)     â”‚    â”‚
â”‚  â”‚  - POST /api/training/{id}/stop (åœæ­¢è®­ç»ƒ)        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TrainingExecutionService                           â”‚    â”‚
â”‚  â”‚  - è§£æJSONé…ç½®                                     â”‚    â”‚
â”‚  â”‚  - æ„å»ºPythonå‘½ä»¤                                   â”‚    â”‚
â”‚  â”‚  - å¼‚æ­¥æ‰§è¡Œè®­ç»ƒè¿›ç¨‹                                 â”‚    â”‚
â”‚  â”‚  - ç®¡ç†è®­ç»ƒç”Ÿå‘½å‘¨æœŸ                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Pythonè®­ç»ƒè„šæœ¬ (train_qwen_vl_distillation.py)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. æ•™å¸ˆæ¨¡å‹åŠ è½½                                     â”‚    â”‚
â”‚  â”‚    Qwen2.5-VL (å†»ç»“æƒé‡)                           â”‚    â”‚
â”‚  â”‚         â†“                                          â”‚    â”‚
â”‚  â”‚    è§†è§‰ç¼–ç å™¨ â†’ æå–ç‰¹å¾ [B, N, 1280]              â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚ 2. å­¦ç”Ÿæ¨¡å‹åŠ è½½                                     â”‚    â”‚
â”‚  â”‚    [ResNet | ViT | YOLO | UNet | LSTM]            â”‚    â”‚
â”‚  â”‚         â†“                                          â”‚    â”‚
â”‚  â”‚    ä»»åŠ¡å¤´ â†’ è¾“å‡º [åˆ†ç±»/æ£€æµ‹/åˆ†å‰²]                   â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚ 3. ç‰¹å¾å¯¹é½å±‚ (å¯é€‰)                                â”‚    â”‚
â”‚  â”‚    Projector: D_teacher â†’ D_student               â”‚    â”‚
â”‚  â”‚    Attention: è·¨æ¨¡æ€ç‰¹å¾å¯¹é½                        â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚ 4. æŸå¤±è®¡ç®—                                         â”‚    â”‚
â”‚  â”‚    â”œâ”€ ç¡¬æ ‡ç­¾æŸå¤± (Task Loss)                       â”‚    â”‚
â”‚  â”‚    â”œâ”€ è½¯æ ‡ç­¾æŸå¤± (KL Divergence)                   â”‚    â”‚
â”‚  â”‚    â”œâ”€ ç‰¹å¾è’¸é¦æŸå¤± (MSE/Cosine)                    â”‚    â”‚
â”‚  â”‚    â””â”€ æ€»æŸå¤± = Î±*L_hard + Î²*L_soft + Î³*L_feat     â”‚    â”‚
â”‚  â”‚                                                    â”‚    â”‚
â”‚  â”‚ 5. è®­ç»ƒå¾ªç¯                                         â”‚    â”‚
â”‚  â”‚    - æ¢¯åº¦ç´¯ç§¯                                       â”‚    â”‚
â”‚  â”‚    - æ··åˆç²¾åº¦è®­ç»ƒ (AMP)                             â”‚    â”‚
â”‚  â”‚    - å­¦ä¹ ç‡è°ƒåº¦                                     â”‚    â”‚
â”‚  â”‚    - å®šæœŸéªŒè¯                                       â”‚    â”‚
â”‚  â”‚    - ä¿å­˜checkpoints                               â”‚    â”‚
â”‚  â”‚    - HTTPå›è°ƒæ›´æ–°è¿›åº¦                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### Pythonç¯å¢ƒ (æ¨èPython 3.9+)

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n qwen-distill python=3.9
conda activate qwen-distill

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…Qwen2.5-VL
pip install transformers>=4.37.0
pip install qwen-vl-utils  # Qwen VLå·¥å…·åº“

# å®‰è£…å…¶ä»–ä¾èµ–
pip install pillow numpy requests tqdm

# å¯é€‰ï¼šå®‰è£…YOLOv8
pip install ultralytics

# å¯é€‰ï¼šå®‰è£…åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
pip install accelerate deepspeed
```

#### æ¨¡å‹ä¸‹è½½

```bash
# æ–¹å¼1ï¼šä½¿ç”¨Hugging Face Hub
# Qwen2.5-VL 8Bæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½

# æ–¹å¼2ï¼šæ‰‹åŠ¨ä¸‹è½½
mkdir -p /data/models/qwen2.5-vl-8b
cd /data/models/qwen2.5-vl-8b
# ä»ModelScopeæˆ–Hugging Faceä¸‹è½½æ¨¡å‹æ–‡ä»¶
```

### 2. æ•°æ®å‡†å¤‡

#### æ•°æ®é›†ç»“æ„

```
/data/datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class_0/
â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”‚   â”œâ”€â”€ img_002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ class_1/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ class_0/
    â””â”€â”€ ...
```

#### æ•°æ®åº“é›†æˆ (TODO)

ä¿®æ”¹ `train_qwen_vl_distillation.py` ä¸­çš„ `MultiTaskDataset` ç±»ï¼š

```python
def __getitem__(self, idx):
    # ä»æ•°æ®åº“åŠ è½½å›¾åƒè·¯å¾„å’Œæ ‡æ³¨
    image_record = self.db.query(
        "SELECT image_path, label FROM dataset WHERE id=?",
        (idx,)
    )

    # åŠ è½½å›¾åƒ
    image = Image.open(image_record['image_path'])
    pixel_values = self.transform(image)

    return {
        'pixel_values': pixel_values,
        'labels': image_record['label']
    }
```

### 3. é…ç½®è®­ç»ƒä»»åŠ¡

#### ç¤ºä¾‹1ï¼šResNet50 åˆ†ç±»ä»»åŠ¡

```bash
python train_qwen_vl_distillation.py \
    --task_id "task_001" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "resnet" \
    --student_model_size "resnet50" \
    --task_type "classification" \
    --num_classes 10 \
    --dataset_path "/data/datasets/train" \
    --val_dataset_path "/data/datasets/val" \
    --image_size 224 \
    --epochs 100 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --optimizer_type "adamw" \
    --lr_scheduler "cosine" \
    --distillation_type "hybrid" \
    --alpha 0.5 --beta 0.3 --gamma 0.2 \
    --align_feature \
    --use_amp \
    --gpu_devices "0" \
    --output_dir "/data/outputs/task_001"
```

#### ç¤ºä¾‹2ï¼šVision Transformer åˆ†ç±»ä»»åŠ¡

```bash
python train_qwen_vl_distillation.py \
    --task_id "task_002" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "vit" \
    --student_model_size "vit-base" \
    --task_type "classification" \
    --num_classes 100 \
    --dataset_path "/data/datasets/imagenet_subset/train" \
    --val_dataset_path "/data/datasets/imagenet_subset/val" \
    --image_size 224 \
    --epochs 50 \
    --batch_size 64 \
    --learning_rate 5e-5 \
    --optimizer_type "adamw" \
    --lr_scheduler "cosine" \
    --weight_decay 0.05 \
    --distillation_type "layer" \
    --temperature 4.0 \
    --align_feature \
    --feature_loss_type "cosine" \
    --use_amp \
    --gpu_devices "0,1" \
    --output_dir "/data/outputs/task_002"
```

#### ç¤ºä¾‹3ï¼šYOLOv8 ç›®æ ‡æ£€æµ‹ä»»åŠ¡

```bash
python train_qwen_vl_distillation.py \
    --task_id "task_003" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "yolov8" \
    --student_model_size "s" \
    --task_type "detection" \
    --num_classes 80 \
    --dataset_path "/data/datasets/coco/train" \
    --val_dataset_path "/data/datasets/coco/val" \
    --image_size 640 \
    --epochs 300 \
    --batch_size 16 \
    --learning_rate 1e-3 \
    --optimizer_type "sgd" \
    --lr_scheduler "cosine" \
    --distillation_type "feature" \
    --gamma 1.0 \
    --feature_loss_type "mse" \
    --gpu_devices "0" \
    --output_dir "/data/outputs/task_003"
```

#### ç¤ºä¾‹4ï¼šUNet å›¾åƒåˆ†å‰²ä»»åŠ¡

```bash
python train_qwen_vl_distillation.py \
    --task_id "task_004" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "unet" \
    --student_model_size "medium" \
    --task_type "segmentation" \
    --num_classes 21 \
    --dataset_path "/data/datasets/voc2012/train" \
    --val_dataset_path "/data/datasets/voc2012/val" \
    --image_size 512 \
    --epochs 150 \
    --batch_size 8 \
    --learning_rate 1e-4 \
    --optimizer_type "adam" \
    --distillation_type "feature" \
    --gamma 1.0 \
    --use_amp \
    --gpu_devices "0" \
    --output_dir "/data/outputs/task_004"
```

#### ç¤ºä¾‹5ï¼šLSTM åºåˆ—åˆ†ç±»ä»»åŠ¡

```bash
python train_qwen_vl_distillation.py \
    --task_id "task_005" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "lstm" \
    --student_model_size "medium" \
    --task_type "classification" \
    --num_classes 10 \
    --dataset_path "/data/datasets/train" \
    --val_dataset_path "/data/datasets/val" \
    --image_size 224 \
    --epochs 100 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --optimizer_type "adam" \
    --distillation_type "feature" \
    --gamma 0.5 \
    --gpu_devices "0" \
    --output_dir "/data/outputs/task_005"
```

---

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### åŸºç¡€é…ç½®

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `--task_id` | str | âœ… | ä»»åŠ¡å”¯ä¸€æ ‡è¯† |
| `--api_base_url` | str | âœ… | åç«¯APIåœ°å€ |
| `--teacher_model_path` | str | âœ… | Qwen2.5-VLæ¨¡å‹è·¯å¾„ |
| `--student_model_type` | str | âœ… | å­¦ç”Ÿæ¨¡å‹ç±»å‹ï¼šresnet/vit/yolov8/unet/lstm |
| `--student_model_size` | str | âœ… | æ¨¡å‹å¤§å°ï¼šresnet50, vit-baseç­‰ |

### ä»»åŠ¡é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--task_type` | str | classification | ä»»åŠ¡ç±»å‹ï¼šclassification/detection/segmentation |
| `--num_classes` | int | 10 | åˆ†ç±»ç±»åˆ«æ•° |
| `--dataset_path` | str | å¿…å¡« | è®­ç»ƒæ•°æ®é›†è·¯å¾„ |
| `--val_dataset_path` | str | å¿…å¡« | éªŒè¯æ•°æ®é›†è·¯å¾„ |
| `--image_size` | int | 224 | è¾“å…¥å›¾åƒå¤§å° |

### è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--epochs` | int | 100 | è®­ç»ƒè½®æ•° |
| `--batch_size` | int | 32 | æ‰¹å¤§å° |
| `--learning_rate` | float | 1e-4 | å­¦ä¹ ç‡ |
| `--optimizer_type` | str | adamw | ä¼˜åŒ–å™¨ï¼šadamw/adam/sgd |
| `--lr_scheduler` | str | cosine | å­¦ä¹ ç‡è°ƒåº¦ï¼šcosine/linear/step |
| `--weight_decay` | float | 0.01 | æƒé‡è¡°å‡ |
| `--grad_accum_steps` | int | 1 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `--max_grad_norm` | float | 1.0 | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |

### è’¸é¦é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--distillation_type` | str | hybrid | è’¸é¦ç±»å‹ï¼šfeature/logit/layer/hybrid |
| `--temperature` | float | 4.0 | è’¸é¦æ¸©åº¦ (ç”¨äºsoftmax) |
| `--alpha` | float | 0.5 | ç¡¬æ ‡ç­¾æƒé‡ (ä»»åŠ¡æŸå¤±) |
| `--beta` | float | 0.3 | è½¯æ ‡ç­¾æƒé‡ (KLæ•£åº¦) |
| `--gamma` | float | 0.2 | ç‰¹å¾è’¸é¦æƒé‡ |
| `--feature_loss_type` | str | mse | ç‰¹å¾æŸå¤±ç±»å‹ï¼šmse/cosine/attention |
| `--align_feature` | flag | False | æ˜¯å¦ä½¿ç”¨ç‰¹å¾å¯¹é½å±‚ |
| `--feature_dim` | int | 768 | ç‰¹å¾å¯¹é½ç»´åº¦ |

### GPUé…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--gpu_devices` | str | 0 | GPUè®¾å¤‡IDï¼Œé€—å·åˆ†éš” (å¦‚"0,1,2") |
| `--use_amp` | flag | False | ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (æ¨è) |

### è¾“å‡ºé…ç½®

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `--output_dir` | str | âœ… | è¾“å‡ºç›®å½•ï¼ˆcheckpointsç­‰ï¼‰ |
| `--checkpoint_interval` | int | 10 | ä¿å­˜checkpointé—´éš”ï¼ˆepochï¼‰ |
| `--log_interval` | int | 50 | æ—¥å¿—æ‰“å°é—´éš”ï¼ˆstepsï¼‰ |

---

## ğŸ“Š è’¸é¦ç­–ç•¥è¯¦è§£

### 1. ç‰¹å¾è’¸é¦ (Feature-based)

**åŸç†**ï¼šä»Qwen2.5-VLçš„è§†è§‰ç¼–ç å™¨æå–ç‰¹å¾ï¼Œè®©å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„ä¸­é—´è¡¨ç¤ºã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… æ‰€æœ‰æ¨¡å‹ç±»å‹ï¼ˆResNetã€ViTã€YOLOã€UNetã€LSTMï¼‰
- âœ… è·¨æ¶æ„è’¸é¦ï¼ˆTransformer â†’ CNNï¼‰
- âœ… ä»»åŠ¡ä¸å®Œå…¨åŒ¹é…çš„æƒ…å†µ

**æŸå¤±å‡½æ•°**ï¼š
```python
# MSEæŸå¤±
L_feature = MSE(student_features, aligned_teacher_features)

# ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
L_feature = 1 - cosine_similarity(student_features, teacher_features)
```

**é…ç½®ç¤ºä¾‹**ï¼š
```bash
--distillation_type "feature" \
--gamma 1.0 \
--feature_loss_type "mse" \
--align_feature
```

### 2. Logitsè’¸é¦ (Logit-based)

**åŸç†**ï¼šä½¿ç”¨Qwen2.5-VLçš„é›¶æ ·æœ¬åˆ†ç±»èƒ½åŠ›ç”Ÿæˆè½¯æ ‡ç­¾ï¼Œé€šè¿‡KLæ•£åº¦è’¸é¦åˆ°å­¦ç”Ÿæ¨¡å‹ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… åˆ†ç±»ä»»åŠ¡ï¼ˆResNetã€ViTã€LSTMï¼‰
- âŒ ä¸é€‚ç”¨äºæ£€æµ‹/åˆ†å‰²ä»»åŠ¡

**æŸå¤±å‡½æ•°**ï¼š
```python
# è½¯æ ‡ç­¾
soft_teacher = softmax(teacher_logits / T)
soft_student = log_softmax(student_logits / T)

# KLæ•£åº¦
L_soft = T^2 * KL_divergence(soft_student, soft_teacher)

# æ€»æŸå¤±
L_total = Î± * L_hard + Î² * L_soft
```

**é…ç½®ç¤ºä¾‹**ï¼š
```bash
--distillation_type "logit" \
--temperature 4.0 \
--alpha 0.5 \
--beta 0.5
```

### 3. ä¸­é—´å±‚è’¸é¦ (Layer-wise)

**åŸç†**ï¼šå¯¹é½æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ä¸­é—´å±‚è¡¨ç¤ºï¼Œç‰¹åˆ«é€‚ç”¨äºTransformeræ¶æ„ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… Vision Transformer â†’ ViT (æ¶æ„ç›¸ä¼¼)
- âš ï¸  éœ€è¦å­¦ç”Ÿæ¨¡å‹ä¹Ÿæ˜¯Transformeræ¶æ„

**æŸå¤±å‡½æ•°**ï¼š
```python
# é€å±‚å¯¹é½
L_layer = Î£ MSE(student_layer_i, teacher_layer_j)
```

**é…ç½®ç¤ºä¾‹**ï¼š
```bash
--distillation_type "layer" \
--student_model_type "vit"
```

### 4. æ··åˆè’¸é¦ (Hybrid)

**åŸç†**ï¼šç»“åˆç‰¹å¾è’¸é¦ã€Logitsè’¸é¦å’Œä»»åŠ¡æŸå¤±ã€‚

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… åˆ†ç±»ä»»åŠ¡ï¼Œè¿½æ±‚æœ€ä½³æ€§èƒ½
- âœ… å­¦ç”Ÿæ¨¡å‹éœ€è¦åŒæ—¶å­¦ä¹ ç‰¹å¾å’Œå†³ç­–è¾¹ç•Œ

**æŸå¤±å‡½æ•°**ï¼š
```python
L_total = Î± * L_hard + Î² * L_soft + Î³ * L_feature
```

**é…ç½®ç¤ºä¾‹**ï¼š
```bash
--distillation_type "hybrid" \
--alpha 0.5 --beta 0.3 --gamma 0.2 \
--temperature 4.0 \
--feature_loss_type "cosine" \
--align_feature
```

---

## ğŸ”§ è¿›é˜¶é…ç½®

### å¤šGPUè®­ç»ƒ

```bash
# æ•°æ®å¹¶è¡Œ
python train_qwen_vl_distillation.py \
    --gpu_devices "0,1,2,3" \
    --batch_size 128 \
    # å…¶ä»–å‚æ•°...

# æ³¨æ„ï¼šå½“å‰å®ç°ä½¿ç”¨å•GPUï¼Œå¤šGPUéœ€è¦é›†æˆtorch.nn.DataParallelæˆ–DDP
```

### æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¨¡æ‹Ÿå¤§æ‰¹é‡ï¼‰

```bash
# å®é™…batch_size = 32ï¼Œæ¨¡æ‹Ÿbatch_size = 32 * 4 = 128
python train_qwen_vl_distillation.py \
    --batch_size 32 \
    --grad_accum_steps 4 \
    # å…¶ä»–å‚æ•°...
```

### æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰

```bash
python train_qwen_vl_distillation.py \
    --use_amp \
    --batch_size 64 \  # å¯ä»¥å¢å¤§batch_size
    # å…¶ä»–å‚æ•°...
```

### ç»§ç»­è®­ç»ƒï¼ˆä»checkpointæ¢å¤ï¼‰

```python
# ä¿®æ”¹train_qwen_vl_distillation.py
# åœ¨main()å‡½æ•°ä¸­æ·»åŠ ï¼š

if args.resume_checkpoint:
    checkpoint = torch.load(args.resume_checkpoint)
    trainer.student_model.load_state_dict(checkpoint['model_state_dict'])
    trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    trainer.current_epoch = checkpoint['epoch']
```

---

## ğŸ“ˆ ç›‘æ§å’Œè°ƒè¯•

### è®­ç»ƒè¿›åº¦ç›‘æ§

è®­ç»ƒè„šæœ¬ä¼šé€šè¿‡HTTPå›è°ƒè‡ªåŠ¨ä¸ŠæŠ¥è¿›åº¦åˆ°åç«¯APIï¼š

```python
# æ¯ä¸ªepochç»“æŸå
POST http://localhost:8080/api/training/progress/{task_id}
{
    "epoch": 10,
    "total_epochs": 100,
    "train_loss": 0.234,
    "val_loss": 0.456,
    "val_accuracy": 92.3,
    "timestamp": "2026-01-11T10:30:00"
}
```

### TensorBoardé›†æˆï¼ˆå¯é€‰ï¼‰

```python
# åœ¨train_qwen_vl_distillation.pyä¸­æ·»åŠ 
from torch.utils.tensorboard import SummaryWriter

class MultiModelDistillationTrainer:
    def __init__(self, config):
        # ...
        self.writer = SummaryWriter(log_dir=config.output_dir)

    def _log_training_step(self, losses):
        self.writer.add_scalar('Loss/total', losses['total_loss'], self.global_step)
        self.writer.add_scalar('Loss/hard', losses['hard_loss'], self.global_step)
        self.writer.add_scalar('Loss/feature', losses['feature_loss'], self.global_step)

# å¯åŠ¨TensorBoard
tensorboard --logdir=/data/outputs/task_001
```

### å¸¸è§é—®é¢˜æ’æŸ¥

#### Q1: CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. å‡å°batch_size
--batch_size 16  # ä»32å‡åˆ°16

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
--batch_size 16 --grad_accum_steps 2

# 3. ä½¿ç”¨æ··åˆç²¾åº¦
--use_amp

# 4. å‡å°å›¾åƒå°ºå¯¸
--image_size 192  # ä»224å‡åˆ°192
```

#### Q2: Qwen2.5-VLåŠ è½½å¤±è´¥

**æ£€æŸ¥**ï¼š
```bash
# éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
ls -lh /data/models/qwen2.5-vl-8b/
# åº”åŒ…å«ï¼šconfig.json, model.safetensors, tokenizer.jsonç­‰

# æµ‹è¯•æ¨¡å‹åŠ è½½
python -c "from transformers import Qwen2VLForConditionalGeneration; \
           model = Qwen2VLForConditionalGeneration.from_pretrained('/data/models/qwen2.5-vl-8b')"
```

#### Q3: ç‰¹å¾ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼š`RuntimeError: The size of tensor a (1280) must match the size of tensor b (768)`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¯ç”¨ç‰¹å¾å¯¹é½å±‚
--align_feature \
--feature_dim 768  # è®¾ç½®ä¸ºå­¦ç”Ÿæ¨¡å‹çš„ç‰¹å¾ç»´åº¦
```

#### Q4: è®­ç»ƒæŸå¤±ä¸ä¸‹é™

**æ’æŸ¥æ­¥éª¤**ï¼š
1. æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦è¿‡å°æˆ–è¿‡å¤§
   ```bash
   --learning_rate 1e-3  # å°è¯•è°ƒæ•´
   ```

2. æ£€æŸ¥è’¸é¦æƒé‡é…ç½®
   ```bash
   # åˆæœŸå¢å¤§ç¡¬æ ‡ç­¾æƒé‡
   --alpha 0.7 --beta 0.2 --gamma 0.1
   ```

3. æ£€æŸ¥æ•°æ®å¢å¼ºæ˜¯å¦è¿‡å¼º
   ```python
   # å‡å°‘æ•°æ®å¢å¼ºå¼ºåº¦
   transforms.ColorJitter(brightness=0.1, contrast=0.1)  # ä»0.2å‡åˆ°0.1
   ```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å­¦ç”Ÿæ¨¡å‹é€‰æ‹©å»ºè®®

| ä»»åŠ¡ç±»å‹ | æ¨èæ¨¡å‹ | ç†ç”± |
|---------|---------|------|
| **å›¾åƒåˆ†ç±»** | ResNet50, ViT-Base | å¹³è¡¡å‡†ç¡®ç‡å’Œé€Ÿåº¦ |
| **ç›®æ ‡æ£€æµ‹** | YOLOv8-s/m | å®æ—¶æ£€æµ‹æ€§èƒ½å¥½ |
| **å›¾åƒåˆ†å‰²** | UNet | ä¸“é—¨è®¾è®¡ç”¨äºåˆ†å‰² |
| **è§†é¢‘/åºåˆ—ä»»åŠ¡** | LSTM | å¤„ç†æ—¶åºä¿¡æ¯ |
| **è¾¹ç¼˜éƒ¨ç½²** | ResNet18, YOLOv8-n | å‚æ•°é‡å°ï¼Œæ¨ç†å¿« |

### 2. è’¸é¦ç­–ç•¥é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èç­–ç•¥ | é…ç½® |
|------|---------|------|
| **åˆ†ç±»ä»»åŠ¡ï¼Œè¿½æ±‚é«˜å‡†ç¡®ç‡** | Hybrid | `--distillation_type hybrid --alpha 0.5 --beta 0.3 --gamma 0.2` |
| **åˆ†ç±»ä»»åŠ¡ï¼Œå¿«é€Ÿæ”¶æ•›** | Feature | `--distillation_type feature --gamma 1.0` |
| **ViTå­¦ç”Ÿæ¨¡å‹** | Layer-wise | `--distillation_type layer` |
| **æ£€æµ‹/åˆ†å‰²ä»»åŠ¡** | Feature | `--distillation_type feature --gamma 1.0` |
| **è·¨æ¶æ„è’¸é¦** | Feature + Align | `--distillation_type feature --align_feature` |

### 3. è¶…å‚æ•°è°ƒä¼˜å»ºè®®

**å­¦ä¹ ç‡**ï¼š
```
ResNet: 1e-4
ViT: 5e-5 (Transformerå¯¹å­¦ä¹ ç‡æ•æ„Ÿ)
YOLO: 1e-3 (æ£€æµ‹ä»»åŠ¡é€šå¸¸éœ€è¦æ›´å¤§å­¦ä¹ ç‡)
UNet: 1e-4
LSTM: 1e-4
```

**Batch Size**ï¼š
```
åˆ†ç±» (ResNet/ViT): 32-64
æ£€æµ‹ (YOLO): 16-32 (å—å›¾åƒå°ºå¯¸å½±å“)
åˆ†å‰² (UNet): 8-16 (æ˜¾å­˜å ç”¨å¤§)
```

**è’¸é¦æ¸©åº¦**ï¼š
```
ç®€å•ä»»åŠ¡ (10ç±»): T=2-3
ä¸­ç­‰ä»»åŠ¡ (100ç±»): T=4-5
å¤æ‚ä»»åŠ¡ (1000ç±»): T=6-8
```

### 4. è®­ç»ƒæµç¨‹å»ºè®®

**é˜¶æ®µ1ï¼šçƒ­èº«è®­ç»ƒï¼ˆ10% epochsï¼‰**
```bash
# ä»…ä½¿ç”¨ç¡¬æ ‡ç­¾æŸå¤±ï¼Œè®©å­¦ç”Ÿæ¨¡å‹å…ˆå­¦ä¼šåŸºæœ¬ä»»åŠ¡
--alpha 1.0 --beta 0.0 --gamma 0.0 \
--lr_scheduler "linear"
```

**é˜¶æ®µ2ï¼šè’¸é¦è®­ç»ƒï¼ˆ80% epochsï¼‰**
```bash
# å®Œæ•´è’¸é¦
--alpha 0.5 --beta 0.3 --gamma 0.2 \
--lr_scheduler "cosine"
```

**é˜¶æ®µ3ï¼šå¾®è°ƒï¼ˆ10% epochsï¼‰**
```bash
# é™ä½å­¦ä¹ ç‡ï¼Œä»…ä½¿ç”¨ç¡¬æ ‡ç­¾
--learning_rate 1e-5 \
--alpha 1.0 --beta 0.0 --gamma 0.0
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### 1. Qwen2.5-VLç‰¹æ€§

- **è¾“å…¥æ ¼å¼**ï¼šQwen2.5-VLæ¥å—å›¾åƒ+æ–‡æœ¬ä½œä¸ºè¾“å…¥
- **è§†è§‰ç¼–ç å™¨**ï¼šæå–çš„ç‰¹å¾ç»´åº¦é€šå¸¸ä¸º1280æˆ–æ›´é«˜
- **é›¶æ ·æœ¬èƒ½åŠ›**ï¼šå¯ä»¥ç”¨äºç”Ÿæˆè½¯æ ‡ç­¾ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
- **æ˜¾å­˜å ç”¨**ï¼š8Bæ¨¡å‹åŠ è½½éœ€è¦çº¦16GBæ˜¾å­˜ï¼ˆFP16ï¼‰

### 2. æ•°æ®é›†è¦æ±‚

- **å›¾åƒæ ¼å¼**ï¼šæ”¯æŒJPEGã€PNGç­‰å¸¸è§æ ¼å¼
- **å›¾åƒå¤§å°**ï¼šå»ºè®®ç»Ÿä¸€resizeåˆ°224x224æˆ–æ›´å¤§
- **æ ‡æ³¨æ ¼å¼**ï¼š
  - åˆ†ç±»ï¼šç±»åˆ«ID (0-N)
  - æ£€æµ‹ï¼šCOCOæ ¼å¼æˆ–YOLOæ ¼å¼
  - åˆ†å‰²ï¼šåƒç´ çº§æ ‡ç­¾å›¾

### 3. è®¡ç®—èµ„æºéœ€æ±‚

| é…ç½® | GPUæ˜¾å­˜ | è®­ç»ƒæ—¶é—´ (100 epochs, 1000æ ·æœ¬) |
|------|---------|--------------------------------|
| **æœ€ä½é…ç½®** | 16GB | ~6å°æ—¶ |
| **æ¨èé…ç½®** | 24GB | ~3å°æ—¶ |
| **é«˜æ€§èƒ½é…ç½®** | 32GB+ | ~1.5å°æ—¶ |

### 4. è®¸å¯è¯å’Œä½¿ç”¨é™åˆ¶

- **Qwen2.5-VL**ï¼šéµå¾ªé˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¨¡å‹è®¸å¯åè®®
- **å­¦ç”Ÿæ¨¡å‹**ï¼šéµå¾ªå„è‡ªçš„å¼€æºè®¸å¯è¯ï¼ˆMITã€Apacheç­‰ï¼‰
- **å•†ä¸šä½¿ç”¨**ï¼šéœ€æŸ¥é˜…Qwen2.5-VLçš„å•†ä¸šä½¿ç”¨æ¡æ¬¾

---

## ğŸ”— å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [Qwen2.5-VLå®˜æ–¹æ–‡æ¡£](https://github.com/QwenLM/Qwen-VL)
- [Hugging Face Transformersæ–‡æ¡£](https://huggingface.co/docs/transformers)
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/stable/index.html)

### ç›¸å…³è®ºæ–‡

1. **çŸ¥è¯†è’¸é¦**ï¼š
   - [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531) (Hinton et al., 2015)

2. **ç‰¹å¾è’¸é¦**ï¼š
   - [FitNets: Hints for Thin Deep Nets](https://arxiv.org/abs/1412.6550) (Romero et al., 2014)

3. **å¤šæ¨¡æ€æ¨¡å‹**ï¼š
   - [Qwen-VL: A Versatile Vision-Language Model](https://arxiv.org/abs/2308.12966)

### ç¤¾åŒºæ”¯æŒ

- **GitHub Issues**ï¼šæŠ¥å‘Šbugå’ŒåŠŸèƒ½è¯·æ±‚
- **Discussions**ï¼šæŠ€æœ¯è®¨è®ºå’Œç»éªŒåˆ†äº«
- **å¾®ä¿¡ç¾¤**ï¼šåŠ å…¥å¼€å‘è€…ç¤¾åŒº

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»£ç éµå¾ª MIT è®¸å¯è¯ã€‚ä½¿ç”¨çš„æ¨¡å‹éœ€éµå¾ªå„è‡ªçš„è®¸å¯åè®®ã€‚

---

**æœ€åæ›´æ–°**: 2026-01-11
**ç»´æŠ¤è€…**: Claude Assistant
**ç‰ˆæœ¬**: 1.0.0
