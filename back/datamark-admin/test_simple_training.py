#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•è®­ç»ƒæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯åŸºæœ¬çš„è®­ç»ƒæµç¨‹ï¼ˆä¸ä¾èµ–Qwen2.5-VLå¤§æ¨¡å‹ï¼‰

æµ‹è¯•å†…å®¹ï¼š
1. ResNet18åœ¨CIFAR-10ä¸Šçš„è®­ç»ƒ
2. è®­ç»ƒå¾ªç¯æ­£ç¡®æ€§
3. GPUåŠ é€Ÿæ•ˆæœ
4. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

ä½œè€…ï¼šClaude Assistant
æ—¥æœŸï¼š2026-01-14
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from pathlib import Path
import time
import sys

print("=" * 70)
print("ğŸš€ ç®€å•è®­ç»ƒæµ‹è¯• - ResNet18 on CIFAR-10")
print("=" * 70)
print()

# ==================== é…ç½® ====================
BATCH_SIZE = 32
NUM_EPOCHS = 2  # åªè®­ç»ƒ2ä¸ªepochï¼Œå¿«é€ŸéªŒè¯
LEARNING_RATE = 0.001
NUM_WORKERS = 2
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print(f"ğŸ“Œ è®­ç»ƒé…ç½®")
print("-" * 70)
print(f"è®¾å¤‡: {DEVICE}")
print(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"è®­ç»ƒè½®æ•°: {NUM_EPOCHS}")
print(f"å­¦ä¹ ç‡: {LEARNING_RATE}")
print()

# ==================== å‡†å¤‡æ•°æ®é›† ====================
print("ğŸ“Œ å‡†å¤‡æ•°æ®é›†")
print("-" * 70)

# æ•°æ®é¢„å¤„ç†
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])

# ä¸‹è½½æ•°æ®é›†ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
dataset_root = Path("./datasets")
dataset_root.mkdir(exist_ok=True)

try:
    print("æ­£åœ¨åŠ è½½CIFAR-10è®­ç»ƒé›†...")
    trainset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=True,
        download=True,
        transform=transform_train
    )
    print(f"âœ… è®­ç»ƒé›†åŠ è½½æˆåŠŸ: {len(trainset)} å¼ å›¾ç‰‡")

    print("æ­£åœ¨åŠ è½½CIFAR-10æµ‹è¯•é›†...")
    testset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=False,
        download=True,
        transform=transform_test
    )
    print(f"âœ… æµ‹è¯•é›†åŠ è½½æˆåŠŸ: {len(testset)} å¼ å›¾ç‰‡")

except Exception as e:
    print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
trainloader = DataLoader(
    trainset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=NUM_WORKERS
)

testloader = DataLoader(
    testset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=NUM_WORKERS
)

print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(trainloader)}")
print(f"   æµ‹è¯•æ‰¹æ¬¡æ•°: {len(testloader)}")
print()

# ==================== åˆ›å»ºæ¨¡å‹ ====================
print("ğŸ“Œ åˆ›å»ºæ¨¡å‹")
print("-" * 70)

try:
    # ä½¿ç”¨ResNet18
    model = torchvision.models.resnet18(pretrained=False, num_classes=10)
    model = model.to(DEVICE)

    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"âœ… ResNet18åˆ›å»ºæˆåŠŸ")
    print(f"   æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params / 1e6:.2f}M")
    print(f"   æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
except Exception as e:
    print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
    sys.exit(1)

print()

# ==================== å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ====================
print("ğŸ“Œ é…ç½®è®­ç»ƒç»„ä»¶")
print("-" * 70)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

print(f"âœ… æŸå¤±å‡½æ•°: CrossEntropyLoss")
print(f"âœ… ä¼˜åŒ–å™¨: Adam (lr={LEARNING_RATE})")
print()

# ==================== è®­ç»ƒå‡½æ•° ====================
def train_one_epoch(epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    print(f"Epoch {epoch + 1}/{NUM_EPOCHS}")
    start_time = time.time()

    for batch_idx, (inputs, labels) in enumerate(trainloader):
        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()

        # ç»Ÿè®¡
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        # æ¯100ä¸ªbatchæ‰“å°ä¸€æ¬¡
        if (batch_idx + 1) % 100 == 0:
            avg_loss = running_loss / (batch_idx + 1)
            acc = 100.0 * correct / total
            print(f"  Batch [{batch_idx + 1}/{len(trainloader)}] "
                  f"Loss: {avg_loss:.4f} | Acc: {acc:.2f}% ({correct}/{total})")

    epoch_time = time.time() - start_time
    avg_loss = running_loss / len(trainloader)
    acc = 100.0 * correct / total

    print(f"  Epochå®Œæˆ! ç”¨æ—¶: {epoch_time:.2f}s | "
          f"å¹³å‡Loss: {avg_loss:.4f} | å‡†ç¡®ç‡: {acc:.2f}%")

    return avg_loss, acc

# ==================== æµ‹è¯•å‡½æ•° ====================
def test():
    """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°"""
    model.eval()
    test_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    avg_loss = test_loss / len(testloader)
    acc = 100.0 * correct / total

    print(f"  æµ‹è¯•é›†ç»“æœ: Loss: {avg_loss:.4f} | Acc: {acc:.2f}% ({correct}/{total})")

    return avg_loss, acc

# ==================== å¼€å§‹è®­ç»ƒ ====================
print("=" * 70)
print("ğŸ‹ï¸  å¼€å§‹è®­ç»ƒ")
print("=" * 70)
print()

training_start = time.time()

try:
    for epoch in range(NUM_EPOCHS):
        train_loss, train_acc = train_one_epoch(epoch)
        print(f"  æ­£åœ¨æµ‹è¯•...")
        test_loss, test_acc = test()
        print()

    total_time = time.time() - training_start
    print("=" * 70)
    print(f"âœ… è®­ç»ƒå®Œæˆ! æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
    print("=" * 70)

except KeyboardInterrupt:
    print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    sys.exit(0)
except Exception as e:
    print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print()

# ==================== æ¨¡å‹ä¿å­˜æµ‹è¯• ====================
print("ğŸ“Œ æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
print("-" * 70)

model_save_dir = Path("./test_models")
model_save_dir.mkdir(exist_ok=True)
model_path = model_save_dir / "resnet18_cifar10_test.pth"

try:
    # ä¿å­˜æ¨¡å‹
    torch.save({
        'epoch': NUM_EPOCHS,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_acc': train_acc,
        'test_acc': test_acc,
    }, model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    print(f"   æ–‡ä»¶å¤§å°: {model_path.stat().st_size / 1024 / 1024:.2f} MB")

    # åŠ è½½æ¨¡å‹
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒå‡†ç¡®ç‡: {checkpoint['train_acc']:.2f}%")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {checkpoint['test_acc']:.2f}%")

except Exception as e:
    print(f"âŒ æ¨¡å‹ä¿å­˜/åŠ è½½å¤±è´¥: {e}")

print()

# ==================== æ€»ç»“ ====================
print("=" * 70)
print("ğŸ“Š æµ‹è¯•æ€»ç»“")
print("=" * 70)
print()

print("âœ… æµ‹è¯•é€šè¿‡çš„é¡¹ç›®:")
print("   - æ•°æ®é›†ä¸‹è½½å’ŒåŠ è½½")
print("   - æ¨¡å‹åˆ›å»ºå’Œç§»åŠ¨åˆ°GPU")
print("   - è®­ç»ƒå¾ªç¯æ‰§è¡Œ")
print("   - å‰å‘å’Œåå‘ä¼ æ’­")
print("   - æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
print()

if torch.cuda.is_available():
    print("ğŸ’¡ GPUåŠ é€Ÿä¿¡æ¯:")
    print(f"   - ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    print(f"   - æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
    print(f"   - æ˜¾å­˜ç¼“å­˜: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB")
else:
    print("âš ï¸  æœªä½¿ç”¨GPUåŠ é€Ÿ")
    print("   å¦‚æœæœ‰NVIDIA GPUï¼Œè¯·å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch")

print()
print("ğŸ“ ä¸‹ä¸€æ­¥:")
print("   1. å¦‚æœæ­¤æµ‹è¯•é€šè¿‡ï¼Œè¯´æ˜åŸºæœ¬è®­ç»ƒç¯å¢ƒæ­£å¸¸")
print("   2. å¯ä»¥ç»§ç»­æµ‹è¯•æ¨¡å‹åŠ è½½: python test_model_loading.py")
print("   3. æœ€åæµ‹è¯•å®Œæ•´è’¸é¦æµç¨‹")
print()

print("=" * 70)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
