#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°æµ‹è¯•ç‰ˆæœ¬ - Qwen2.5-VLçŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬

ç”¨é€”ï¼šè„±ç¦»å‰åç«¯ç³»ç»Ÿï¼Œç‹¬ç«‹è¿è¡Œæµ‹è¯•è®­ç»ƒè„šæœ¬
é€‚åˆï¼šéªŒè¯æ•°æ®é›†åŠ è½½ã€æ¨¡å‹è®­ç»ƒæµç¨‹æ˜¯å¦æ­£å¸¸

ä½¿ç”¨æ–¹æ³•ï¼š
    python test_local.py

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2026-01-26
"""

import os
import sys
import time
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# Qwen2.5-VLç›¸å…³å¯¼å…¥
try:
    from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
    QWEN_AVAILABLE = True
except ImportError:
    QWEN_AVAILABLE = False
    warnings.warn("âš ï¸ Qwen2_5_VLæ¨¡å‹åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

# å°æ¨¡å‹ç›¸å…³å¯¼å…¥
import torchvision.models as models
from transformers import (
    AutoConfig,
    AutoModelForImageClassification,
    AutoImageProcessor,
)
from peft import LoraConfig, get_peft_model, TaskType


# ==================== é…ç½®ç±» ====================

class SimpleConfig:
    """ç®€åŒ–çš„è®­ç»ƒé…ç½®ç±»"""

    def __init__(self):
        # ========== å…³é”®é…ç½®ï¼ˆéœ€è¦ä¿®æ”¹ï¼‰ ==========
        # æ•°æ®é›†æ ¹ç›®å½•ï¼ˆä¿®æ”¹ä¸ºæ‚¨çš„å®é™…è·¯å¾„ï¼‰
        self.datasets_root = r"D:\pythonProject2\datasets"

        # æ•°æ®é›†IDï¼ˆå­ç›®å½•åï¼‰
        self.dataset_id = "cifar10"

        # æ•™å¸ˆæ¨¡å‹è·¯å¾„
        self.teacher_path = r"D:\pythonProject2\models\Qwen2___5-VL-3B-Instruct"

        # è¾“å‡ºç›®å½•
        self.output_dir = r"D:\pythonProject2\test_output"

        # ========== ä»»åŠ¡é…ç½® ==========
        self.task_type = "classification"  # classification/detection/segmentation
        self.num_classes = 10  # CIFAR-10æœ‰10ä¸ªç±»åˆ«
        self.image_size = 224

        # ========== å­¦ç”Ÿæ¨¡å‹é…ç½® ==========
        self.student_model_type = "resnet"  # resnet/vit/yolov8/unet/lstm
        self.student_model_size = "resnet18"  # resnet18/resnet50/vit-baseç­‰

        # ========== è®­ç»ƒå‚æ•° ==========
        self.epochs = 2  # æµ‹è¯•ç”¨ï¼Œåªè®­ç»ƒ2ä¸ªepoch
        self.batch_size = 8  # è¾ƒå°çš„batch sizeï¼Œé™ä½å†…å­˜å ç”¨
        self.learning_rate = 0.0001

        # ========== LoRAé…ç½® ==========
        self.lora_rank = 8
        self.lora_alpha = 16
        self.lora_dropout = 0.1

        # ========== çŸ¥è¯†è’¸é¦å‚æ•° ==========
        self.temperature = 4.0
        self.hard_label_weight = 0.3
        self.soft_label_weight = 0.7
        self.distillation_type = "logit"  # logit/feature/hybrid

        # ========== è®¾å¤‡é…ç½® ==========
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # ========== ä¼˜åŒ–å™¨é…ç½® ==========
        self.optimizer_type = "adamw"
        self.weight_decay = 0.01

        # ========== å…¶ä»– ==========
        self.save_interval = 1  # æ¯ä¸ªepochéƒ½ä¿å­˜
        self.log_interval = 10  # æ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡


# ==================== æ•°æ®é›†ç±» ====================

class CIFAR10Dataset(Dataset):
    """
    CIFAR-10æ•°æ®é›†åŠ è½½å™¨

    æœŸæœ›çš„ç›®å½•ç»“æ„ï¼š
    dataset_root/cifar10/
      â”œâ”€â”€ train/
      â”‚   â”œâ”€â”€ airplane/
      â”‚   â”œâ”€â”€ automobile/
      â”‚   â””â”€â”€ ...
      â””â”€â”€ val/
          â”œâ”€â”€ airplane/
          â””â”€â”€ ...
    """

    def __init__(
        self,
        dataset_path: str,
        image_size: int = 224,
        mode: str = 'train'
    ):
        self.dataset_path = dataset_path
        self.image_size = image_size
        self.mode = mode

        # å­˜å‚¨æ‰€æœ‰å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        self.image_paths = []
        self.labels = []
        self.class_names = []

        # åŠ è½½æ•°æ®é›†
        if os.path.exists(dataset_path):
            self._load_dataset()
        else:
            print(f"âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            print(f"è¯·å…ˆè¿è¡Œ convert_cifar10.py è½¬æ¢æ•°æ®é›†")
            sys.exit(1)

        # æ•°æ®å¢å¼º
        if mode == 'train':
            self.transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])

    def _load_dataset(self):
        """ä»ç›®å½•ç»“æ„åŠ è½½æ•°æ®é›†"""
        print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {self.dataset_path}")

        # è·å–æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        class_folders = sorted([d for d in os.listdir(self.dataset_path)
                               if os.path.isdir(os.path.join(self.dataset_path, d))])

        if not class_folders:
            print(f"âŒ é”™è¯¯: åœ¨ {self.dataset_path} ä¸­æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹")
            sys.exit(1)

        self.class_names = class_folders
        print(f"âœ… æ‰¾åˆ° {len(self.class_names)} ä¸ªç±»åˆ«: {self.class_names}")

        # éå†æ¯ä¸ªç±»åˆ«æ–‡ä»¶å¤¹
        for class_idx, class_name in enumerate(self.class_names):
            class_dir = os.path.join(self.dataset_path, class_name)

            # è·å–è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_files = [f for f in os.listdir(class_dir)
                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

            for img_file in image_files:
                img_path = os.path.join(class_dir, img_file)
                self.image_paths.append(img_path)
                self.labels.append(class_idx)

        print(f"âœ… åŠ è½½å®Œæˆ: å…± {len(self.image_paths)} å¼ å›¾åƒ")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥ {img_path}: {e}")
            # ç”Ÿæˆéšæœºå›¾åƒä½œä¸ºåå¤‡
            image_array = np.random.randint(0, 255, (self.image_size, self.image_size, 3), dtype=np.uint8)
            image = Image.fromarray(image_array)

        # åº”ç”¨å˜æ¢
        image = self.transform(image)

        return {'pixel_values': image, 'labels': label}


# ==================== å­¦ç”Ÿæ¨¡å‹åŠ è½½å™¨ ====================

class StudentModelLoader:
    """å­¦ç”Ÿæ¨¡å‹åŠ è½½å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    @staticmethod
    def load_resnet(model_size: str, num_classes: int):
        """åŠ è½½ResNetæ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½å­¦ç”Ÿæ¨¡å‹: ResNet-{model_size}")

        if model_size == "resnet18":
            model = models.resnet18(pretrained=False)
        elif model_size == "resnet34":
            model = models.resnet34(pretrained=False)
        elif model_size == "resnet50":
            model = models.resnet50(pretrained=False)
        else:
            model = models.resnet18(pretrained=False)

        # ä¿®æ”¹æœ€åä¸€å±‚ä»¥åŒ¹é…ç±»åˆ«æ•°
        model.fc = nn.Linear(model.fc.in_features, num_classes)

        return model


# ==================== ç®€åŒ–çš„è®­ç»ƒå™¨ ====================

class SimpleTrainer:
    """ç®€åŒ–çš„è®­ç»ƒå™¨ï¼ˆä¸ä¾èµ–åç«¯APIï¼‰"""

    def __init__(self, config: SimpleConfig):
        self.config = config

        print("\n" + "=" * 60)
        print("æœ¬åœ°æµ‹è¯•è®­ç»ƒå™¨åˆå§‹åŒ–")
        print("=" * 60)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        print(f"âœ… è¾“å‡ºç›®å½•: {config.output_dir}")

        # åŠ è½½æ•°æ®é›†
        train_path = os.path.join(config.datasets_root, config.dataset_id, "train")
        val_path = os.path.join(config.datasets_root, config.dataset_id, "val")

        print(f"\nè®­ç»ƒé›†è·¯å¾„: {train_path}")
        print(f"éªŒè¯é›†è·¯å¾„: {val_path}")

        self.train_dataset = CIFAR10Dataset(train_path, config.image_size, mode='train')
        self.val_dataset = CIFAR10Dataset(val_path, config.image_size, mode='val')

        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=config.batch_size,
            shuffle=True,
            num_workers=0  # Windowsä¸Šè®¾ä¸º0é¿å…multiprocessingé—®é¢˜
        )
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=0
        )

        print(f"\nâœ… è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_dataset)}")
        print(f"âœ… éªŒè¯æ ·æœ¬æ•°: {len(self.val_dataset)}")
        print(f"âœ… è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}")

        # åŠ è½½å­¦ç”Ÿæ¨¡å‹
        print(f"\næ­£åœ¨åŠ è½½å­¦ç”Ÿæ¨¡å‹...")
        self.student_model = StudentModelLoader.load_resnet(
            config.student_model_size,
            config.num_classes
        ).to(config.device)

        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            self.student_model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )

        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()

        print(f"âœ… è®¾å¤‡: {config.device}")
        print(f"âœ… å­¦ç”Ÿæ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.student_model.parameters()):,}")

    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.student_model.train()
        total_loss = 0
        correct = 0
        total = 0

        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch}/{self.config.epochs}")

        for batch_idx, batch in enumerate(pbar):
            images = batch['pixel_values'].to(self.config.device)
            labels = batch['labels'].to(self.config.device)

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            outputs = self.student_model(images)
            loss = self.criterion(outputs, labels)

            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()

            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % self.config.log_interval == 0:
                acc = 100. * correct / total
                avg_loss = total_loss / (batch_idx + 1)
                pbar.set_postfix({
                    'loss': f'{avg_loss:.4f}',
                    'acc': f'{acc:.2f}%'
                })

        # Epochç»Ÿè®¡
        avg_loss = total_loss / len(self.train_loader)
        acc = 100. * correct / total

        print(f"\nğŸ“Š Epoch {epoch} è®­ç»ƒç»“æœ:")
        print(f"   Loss: {avg_loss:.4f}")
        print(f"   Accuracy: {acc:.2f}%")

        return avg_loss, acc

    def validate(self):
        """éªŒè¯æ¨¡å‹"""
        self.student_model.eval()
        total_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="éªŒè¯ä¸­"):
                images = batch['pixel_values'].to(self.config.device)
                labels = batch['labels'].to(self.config.device)

                outputs = self.student_model(images)
                loss = self.criterion(outputs, labels)

                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.val_loader)
        acc = 100. * correct / total

        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   Loss: {avg_loss:.4f}")
        print(f"   Accuracy: {acc:.2f}%")

        return avg_loss, acc

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "=" * 60)
        print("å¼€å§‹è®­ç»ƒ")
        print("=" * 60)

        best_acc = 0
        start_time = time.time()

        for epoch in range(1, self.config.epochs + 1):
            print(f"\n{'=' * 60}")
            print(f"Epoch {epoch}/{self.config.epochs}")
            print('=' * 60)

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(epoch)

            # éªŒè¯
            val_loss, val_acc = self.validate()

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                save_path = os.path.join(self.config.output_dir, "best_model.pth")
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.student_model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'train_acc': train_acc,
                    'val_acc': val_acc,
                    'best_acc': best_acc,
                }, save_path)
                print(f"\nğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {save_path} (Acc: {best_acc:.2f}%)")

        # è®­ç»ƒç»“æŸ
        elapsed_time = time.time() - start_time
        print("\n" + "=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {elapsed_time/60:.2f} åˆ†é’Ÿ")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
        print(f"æ¨¡å‹ä¿å­˜ä½ç½®: {self.config.output_dir}")


# ==================== ä¸»å‡½æ•° ====================

def main():
    print("\n" + "=" * 60)
    print("Qwen2.5-VL çŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬ - æœ¬åœ°æµ‹è¯•ç‰ˆ")
    print("=" * 60)

    # åˆ›å»ºé…ç½®
    config = SimpleConfig()

    # æ‰“å°é…ç½®ä¿¡æ¯
    print("\nğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"   æ•°æ®é›†æ ¹ç›®å½•: {config.datasets_root}")
    print(f"   æ•°æ®é›†ID: {config.dataset_id}")
    print(f"   æ•™å¸ˆæ¨¡å‹: {config.teacher_path}")
    print(f"   å­¦ç”Ÿæ¨¡å‹: {config.student_model_type}-{config.student_model_size}")
    print(f"   ä»»åŠ¡ç±»å‹: {config.task_type}")
    print(f"   ç±»åˆ«æ•°: {config.num_classes}")
    print(f"   è®­ç»ƒè½®æ•°: {config.epochs}")
    print(f"   æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"   å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"   è¾“å‡ºç›®å½•: {config.output_dir}")

    # æ£€æŸ¥å…³é”®è·¯å¾„
    print("\nğŸ” æ£€æŸ¥è·¯å¾„...")
    train_path = os.path.join(config.datasets_root, config.dataset_id, "train")
    val_path = os.path.join(config.datasets_root, config.dataset_id, "val")

    if not os.path.exists(train_path):
        print(f"âŒ é”™è¯¯: è®­ç»ƒé›†è·¯å¾„ä¸å­˜åœ¨: {train_path}")
        print(f"è¯·å…ˆè¿è¡Œ convert_cifar10.py è½¬æ¢CIFAR-10æ•°æ®é›†")
        return

    if not os.path.exists(val_path):
        print(f"âŒ é”™è¯¯: éªŒè¯é›†è·¯å¾„ä¸å­˜åœ¨: {val_path}")
        print(f"è¯·å…ˆè¿è¡Œ convert_cifar10.py è½¬æ¢CIFAR-10æ•°æ®é›†")
        return

    print("âœ… æ‰€æœ‰è·¯å¾„æ£€æŸ¥é€šè¿‡")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SimpleTrainer(config)

    # å¼€å§‹è®­ç»ƒ
    trainer.train()

    print("\nâœ… æµ‹è¯•è¿è¡Œå®Œæˆï¼")
    print("å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œå¯ä»¥å°†æ­¤è„šæœ¬é›†æˆåˆ°å‰åç«¯ç³»ç»Ÿä¸­ã€‚")


if __name__ == "__main__":
    main()
