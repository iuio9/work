#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°æµ‹è¯•ç‰ˆæœ¬ - Qwen2.5-VLçŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬

ç”¨é€”ï¼šè„±ç¦»å‰åç«¯ç³»ç»Ÿï¼Œç‹¬ç«‹è¿è¡Œæµ‹è¯•çŸ¥è¯†è’¸é¦è®­ç»ƒ
ä¿ç•™å®Œæ•´çš„è’¸é¦é€»è¾‘ï¼šæ•™å¸ˆæ¨¡å‹(Qwen) -> å­¦ç”Ÿæ¨¡å‹(ResNet)

ä½¿ç”¨æ–¹æ³•ï¼š
    python test_local.py

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2026-01-27
"""

import os
import sys
import time
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# Qwen2.5-VLç›¸å…³å¯¼å…¥
try:
    from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
    QWEN_AVAILABLE = True
except ImportError:
    QWEN_AVAILABLE = False
    warnings.warn("âš ï¸ Qwen2_5_VLæ¨¡å‹åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹")

# å°æ¨¡å‹ç›¸å…³å¯¼å…¥
import torchvision.models as models
from peft import LoraConfig, get_peft_model, TaskType


# ==================== é…ç½®ç±» ====================

class SimpleConfig:
    """ç®€åŒ–çš„è®­ç»ƒé…ç½®ç±»"""

    def __init__(self):
        # ========== å…³é”®é…ç½®ï¼ˆéœ€è¦ä¿®æ”¹ï¼‰ ==========
        # æ•°æ®é›†æ ¹ç›®å½•ï¼ˆä¿®æ”¹ä¸ºæ‚¨çš„å®é™…è·¯å¾„ï¼‰
        self.datasets_root = r"D:\pythonProject2\datasets"
        self.dataset_id = "cifar10"

        # æ•™å¸ˆæ¨¡å‹è·¯å¾„ï¼ˆQwen2.5-VLï¼‰
        self.teacher_path = r"D:\pythonProject2\models\Qwen2___5-VL-3B-Instruct"

        # è¾“å‡ºç›®å½•
        self.output_dir = r"D:\pythonProject2\test_output"

        # ========== æ˜¯å¦ä½¿ç”¨çœŸå®Qwenæ¨¡å‹ ==========
        # True: åŠ è½½çœŸå®Qwenæ¨¡å‹ï¼ˆéœ€è¦å¤§é‡å†…å­˜ï¼Œè®­ç»ƒæ…¢ä½†å®Œæ•´ï¼‰
        # False: ä½¿ç”¨æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼ŒéªŒè¯æµç¨‹ï¼‰
        self.use_real_teacher = False  # æ”¹ä¸ºTrueä»¥ä½¿ç”¨çœŸå®Qwenæ¨¡å‹

        # ========== ä»»åŠ¡é…ç½® ==========
        self.task_type = "classification"
        self.num_classes = 10  # CIFAR-10
        self.image_size = 224

        # ========== å­¦ç”Ÿæ¨¡å‹é…ç½® ==========
        self.student_model_type = "resnet"
        self.student_model_size = "resnet18"

        # ========== è®­ç»ƒå‚æ•° ==========
        self.epochs = 2  # æµ‹è¯•ç”¨
        self.batch_size = 8
        self.learning_rate = 0.0001

        # ========== LoRAé…ç½® ==========
        self.lora_rank = 8
        self.lora_alpha = 16
        self.lora_dropout = 0.1

        # ========== çŸ¥è¯†è’¸é¦å‚æ•° ==========
        self.temperature = 4.0
        self.hard_label_weight = 0.3  # ç¡¬æ ‡ç­¾æƒé‡
        self.soft_label_weight = 0.7  # è½¯æ ‡ç­¾æƒé‡
        self.distillation_type = "feature"  # logit/feature/hybrid
        self.feature_loss_type = "mse"  # mse/cosine

        # ========== è®¾å¤‡é…ç½® ==========
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # ========== ä¼˜åŒ–å™¨é…ç½® ==========
        self.optimizer_type = "adamw"
        self.weight_decay = 0.01


# ==================== æ•°æ®é›†ç±» ====================

class CIFAR10Dataset(Dataset):
    """CIFAR-10æ•°æ®é›†åŠ è½½å™¨"""

    def __init__(self, dataset_path: str, image_size: int = 224, mode: str = 'train'):
        self.dataset_path = dataset_path
        self.image_size = image_size
        self.mode = mode

        self.image_paths = []
        self.labels = []
        self.class_names = []

        if os.path.exists(dataset_path):
            self._load_dataset()
        else:
            print(f"âŒ é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            sys.exit(1)

        # æ•°æ®å¢å¼º
        if mode == 'train':
            self.transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((image_size, image_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
            ])

    def _load_dataset(self):
        """ä»ç›®å½•ç»“æ„åŠ è½½æ•°æ®é›†"""
        print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {self.dataset_path}")

        class_folders = sorted([d for d in os.listdir(self.dataset_path)
                               if os.path.isdir(os.path.join(self.dataset_path, d))])

        if not class_folders:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶å¤¹")
            sys.exit(1)

        self.class_names = class_folders
        print(f"âœ… æ‰¾åˆ° {len(self.class_names)} ä¸ªç±»åˆ«: {self.class_names}")

        for class_idx, class_name in enumerate(self.class_names):
            class_dir = os.path.join(self.dataset_path, class_name)
            image_files = [f for f in os.listdir(class_dir)
                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

            for img_file in image_files:
                img_path = os.path.join(class_dir, img_file)
                self.image_paths.append(img_path)
                self.labels.append(class_idx)

        print(f"âœ… åŠ è½½å®Œæˆ: å…± {len(self.image_paths)} å¼ å›¾åƒ")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥: {e}")
            image_array = np.random.randint(0, 255, (self.image_size, self.image_size, 3), dtype=np.uint8)
            image = Image.fromarray(image_array)

        image = self.transform(image)
        return {'pixel_values': image, 'labels': label}


# ==================== æ¨¡å‹åŠ è½½å™¨ ====================

class TeacherModelLoader:
    """æ•™å¸ˆæ¨¡å‹åŠ è½½å™¨"""

    @staticmethod
    def load_qwen2vl(model_path: str, device: torch.device, use_real: bool = True):
        """åŠ è½½Qwen2.5-VLæ¨¡å‹"""
        if not use_real or not QWEN_AVAILABLE:
            print("ğŸ“¦ ä½¿ç”¨æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹ï¼ˆå¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼‰")
            return None, None

        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½Qwen2.5-VLæ•™å¸ˆæ¨¡å‹: {model_path}")
        print("âš ï¸ æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´å’Œå¤§é‡å†…å­˜...")

        try:
            model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
                model_path,
                torch_dtype="auto",
                device_map="cpu"  # å…ˆåŠ è½½åˆ°CPUï¼Œé¿å…GPUå†…å­˜ä¸è¶³
            )
            processor = AutoProcessor.from_pretrained(model_path)
            print("âœ… æ•™å¸ˆæ¨¡å‹åŠ è½½æˆåŠŸ")
            return model, processor
        except Exception as e:
            print(f"âŒ åŠ è½½æ•™å¸ˆæ¨¡å‹å¤±è´¥: {e}")
            print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹")
            return None, None


class StudentModelLoader:
    """å­¦ç”Ÿæ¨¡å‹åŠ è½½å™¨"""

    @staticmethod
    def load_resnet(model_size: str, num_classes: int):
        """åŠ è½½ResNetæ¨¡å‹"""
        print(f"ğŸ“¦ åŠ è½½å­¦ç”Ÿæ¨¡å‹: ResNet-{model_size}")

        if model_size == "resnet18":
            model = models.resnet18(pretrained=False)
        elif model_size == "resnet34":
            model = models.resnet34(pretrained=False)
        elif model_size == "resnet50":
            model = models.resnet50(pretrained=False)
        else:
            model = models.resnet18(pretrained=False)

        # ä¿®æ”¹æœ€åä¸€å±‚
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        return model


# ==================== çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨ ====================

class DistillationTrainer:
    """çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨ï¼ˆä¿ç•™å®Œæ•´è’¸é¦é€»è¾‘ï¼‰"""

    def __init__(self, config: SimpleConfig):
        self.config = config

        print("\n" + "=" * 60)
        print("çŸ¥è¯†è’¸é¦è®­ç»ƒå™¨åˆå§‹åŒ–")
        print("=" * 60)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)

        # åŠ è½½æ•™å¸ˆæ¨¡å‹
        self.teacher_model, self.teacher_processor = TeacherModelLoader.load_qwen2vl(
            config.teacher_path,
            config.device,
            use_real=config.use_real_teacher
        )

        # åŠ è½½å­¦ç”Ÿæ¨¡å‹
        self.student_model = StudentModelLoader.load_resnet(
            config.student_model_size,
            config.num_classes
        ).to(config.device)

        # æ³¨å†Œhookæå–å­¦ç”Ÿç‰¹å¾
        self.student_feature_map = None

        def hook_fn(module, input, output):
            self.student_feature_map = output

        self.student_model.avgpool.register_forward_hook(hook_fn)

        # åŠ è½½æ•°æ®é›†
        train_path = os.path.join(config.datasets_root, config.dataset_id, "train")
        val_path = os.path.join(config.datasets_root, config.dataset_id, "val")

        self.train_dataset = CIFAR10Dataset(train_path, config.image_size, mode='train')
        self.val_dataset = CIFAR10Dataset(val_path, config.image_size, mode='val')

        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=config.batch_size,
            shuffle=True,
            num_workers=0
        )
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=0
        )

        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            self.student_model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )

        # æŸå¤±å‡½æ•°
        self.ce_loss = nn.CrossEntropyLoss()
        self.mse_loss = nn.MSELoss()
        self.kl_loss = nn.KLDivLoss(reduction='batchmean')

        print(f"âœ… è®¾å¤‡: {config.device}")
        print(f"âœ… æ•™å¸ˆæ¨¡å‹: {'çœŸå®Qwen' if self.teacher_model else 'æ¨¡æ‹Ÿæ¨¡å‹'}")
        print(f"âœ… å­¦ç”Ÿæ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.student_model.parameters()):,}")
        print(f"âœ… è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
        print(f"âœ… éªŒè¯æ ·æœ¬: {len(self.val_dataset)}")

    def extract_teacher_features(self, images: torch.Tensor):
        """æå–æ•™å¸ˆæ¨¡å‹ç‰¹å¾"""
        batch_size = images.size(0)

        # æ¨¡æ‹Ÿæ¨¡å¼
        if self.teacher_model is None:
            return {
                'vision_features': torch.randn(batch_size, 256, 1024).to(self.config.device)
            }

        # çœŸå®Qwenæ¨¡å‹
        pil_images = [transforms.ToPILImage()(img.cpu()) for img in images]

        inputs = self.teacher_processor(
            images=pil_images,
            text=["image"] * batch_size,
            return_tensors="pt",
        )

        for k, v in inputs.items():
            if k == "input_ids":
                inputs[k] = v.long().to(self.config.device)
            else:
                inputs[k] = v.to(self.config.device)

        with torch.no_grad():
            outputs = self.teacher_model.visual(**inputs, output_hidden_states=True)
            return {
                'vision_features': outputs.last_hidden_state
            }

    def compute_distillation_loss(
        self,
        student_output: torch.Tensor,
        teacher_features: Dict[str, torch.Tensor],
        labels: torch.Tensor
    ) -> Dict[str, torch.Tensor]:
        """è®¡ç®—çŸ¥è¯†è’¸é¦æŸå¤±"""
        losses = {}

        # 1. ç¡¬æ ‡ç­¾æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
        hard_loss = self.ce_loss(student_output, labels)
        losses['hard_loss'] = hard_loss

        # 2. è½¯æ ‡ç­¾æŸå¤±ï¼ˆKLæ•£åº¦ - ç®€åŒ–ç‰ˆï¼‰
        # åœ¨å®Œæ•´å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨æ•™å¸ˆæ¨¡å‹çš„logits
        soft_loss = torch.tensor(0.0).to(self.config.device)
        losses['soft_loss'] = soft_loss

        # 3. ç‰¹å¾è’¸é¦æŸå¤±
        if self.config.distillation_type in ['feature', 'hybrid']:
            # æå–å­¦ç”Ÿç‰¹å¾
            if self.student_feature_map is not None:
                student_features = self.student_feature_map.flatten(1)  # [B, D]
            else:
                student_features = student_output

            # æ•™å¸ˆç‰¹å¾
            teacher_vis_features = teacher_features['vision_features']  # [B, N, D]
            teacher_pooled = teacher_vis_features.mean(dim=1)  # [B, D]

            # å¯¹é½ç»´åº¦
            if student_features.shape != teacher_pooled.shape:
                # ç®€å•æŠ•å½±
                if student_features.shape[1] != teacher_pooled.shape[1]:
                    if student_features.shape[1] > teacher_pooled.shape[1]:
                        student_features = F.adaptive_avg_pool1d(
                            student_features.unsqueeze(1),
                            teacher_pooled.shape[1]
                        ).squeeze(1)
                    else:
                        teacher_pooled = F.adaptive_avg_pool1d(
                            teacher_pooled.unsqueeze(1),
                            student_features.shape[1]
                        ).squeeze(1)

            # è®¡ç®—ç‰¹å¾æŸå¤±
            if self.config.feature_loss_type == 'mse':
                feature_loss = self.mse_loss(student_features, teacher_pooled)
            elif self.config.feature_loss_type == 'cosine':
                student_norm = F.normalize(student_features, dim=-1)
                teacher_norm = F.normalize(teacher_pooled, dim=-1)
                feature_loss = 1 - F.cosine_similarity(student_norm, teacher_norm).mean()
            else:
                feature_loss = torch.tensor(0.0).to(self.config.device)

            losses['feature_loss'] = feature_loss
        else:
            losses['feature_loss'] = torch.tensor(0.0).to(self.config.device)

        # 4. æ€»æŸå¤±
        total_loss = (
            self.config.hard_label_weight * losses['hard_loss'] +
            self.config.soft_label_weight * losses['soft_loss'] +
            losses['feature_loss']
        )
        losses['total_loss'] = total_loss

        return losses

    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.student_model.train()
        epoch_losses = {'total_loss': 0.0, 'hard_loss': 0.0, 'soft_loss': 0.0, 'feature_loss': 0.0}
        correct = 0
        total = 0

        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch}/{self.config.epochs}")

        for batch_idx, batch in enumerate(pbar):
            images = batch['pixel_values'].to(self.config.device)
            labels = batch['labels'].to(self.config.device)

            # æå–æ•™å¸ˆç‰¹å¾
            teacher_features = self.extract_teacher_features(images)

            # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            student_output = self.student_model(images)

            # è®¡ç®—è’¸é¦æŸå¤±
            losses = self.compute_distillation_loss(student_output, teacher_features, labels)

            # åå‘ä¼ æ’­
            losses['total_loss'].backward()
            self.optimizer.step()

            # ç»Ÿè®¡
            for k in epoch_losses.keys():
                epoch_losses[k] += losses[k].item()

            _, predicted = student_output.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            # æ›´æ–°è¿›åº¦æ¡
            if (batch_idx + 1) % 10 == 0:
                acc = 100. * correct / total
                pbar.set_postfix({
                    'loss': f'{losses["total_loss"].item():.4f}',
                    'hard': f'{losses["hard_loss"].item():.3f}',
                    'feat': f'{losses["feature_loss"].item():.3f}',
                    'acc': f'{acc:.2f}%'
                })

        # Epochç»Ÿè®¡
        for k in epoch_losses.keys():
            epoch_losses[k] /= len(self.train_loader)
        acc = 100. * correct / total

        print(f"\nğŸ“Š Epoch {epoch} è®­ç»ƒç»“æœ:")
        print(f"   Total Loss: {epoch_losses['total_loss']:.4f}")
        print(f"   Hard Loss: {epoch_losses['hard_loss']:.4f}")
        print(f"   Feature Loss: {epoch_losses['feature_loss']:.4f}")
        print(f"   Accuracy: {acc:.2f}%")

        return epoch_losses, acc

    def validate(self):
        """éªŒè¯æ¨¡å‹"""
        self.student_model.eval()
        total_loss = 0
        correct = 0
        total = 0

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="éªŒè¯ä¸­"):
                images = batch['pixel_values'].to(self.config.device)
                labels = batch['labels'].to(self.config.device)

                outputs = self.student_model(images)
                loss = self.ce_loss(outputs, labels)

                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        avg_loss = total_loss / len(self.val_loader)
        acc = 100. * correct / total

        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   Loss: {avg_loss:.4f}")
        print(f"   Accuracy: {acc:.2f}%")

        return avg_loss, acc

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "=" * 60)
        print("å¼€å§‹çŸ¥è¯†è’¸é¦è®­ç»ƒ")
        print("=" * 60)

        best_acc = 0
        start_time = time.time()

        for epoch in range(1, self.config.epochs + 1):
            print(f"\n{'=' * 60}")
            print(f"Epoch {epoch}/{self.config.epochs}")
            print('=' * 60)

            # è®­ç»ƒ
            train_losses, train_acc = self.train_epoch(epoch)

            # éªŒè¯
            val_loss, val_acc = self.validate()

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                save_path = os.path.join(self.config.output_dir, "best_distilled_model.pth")
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.student_model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'train_acc': train_acc,
                    'val_acc': val_acc,
                    'best_acc': best_acc,
                    'config': vars(self.config)
                }, save_path)
                print(f"\nğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {save_path} (Acc: {best_acc:.2f}%)")

        # è®­ç»ƒç»“æŸ
        elapsed_time = time.time() - start_time
        print("\n" + "=" * 60)
        print("âœ… çŸ¥è¯†è’¸é¦è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {elapsed_time/60:.2f} åˆ†é’Ÿ")
        print(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
        print(f"è’¸é¦é…ç½®:")
        print(f"  - ç¡¬æ ‡ç­¾æƒé‡: {self.config.hard_label_weight}")
        print(f"  - è½¯æ ‡ç­¾æƒé‡: {self.config.soft_label_weight}")
        print(f"  - ç‰¹å¾è’¸é¦ç±»å‹: {self.config.distillation_type}")
        print(f"  - ç‰¹å¾æŸå¤±ç±»å‹: {self.config.feature_loss_type}")


# ==================== ä¸»å‡½æ•° ====================

def main():
    print("\n" + "=" * 60)
    print("Qwen2.5-VL çŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬ - æœ¬åœ°æµ‹è¯•ç‰ˆ")
    print("ï¼ˆä¿ç•™å®Œæ•´è’¸é¦é€»è¾‘ï¼‰")
    print("=" * 60)

    # åˆ›å»ºé…ç½®
    config = SimpleConfig()

    # æ‰“å°é…ç½®
    print("\nğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"   æ•°æ®é›†: {config.datasets_root}/{config.dataset_id}")
    print(f"   æ•™å¸ˆæ¨¡å‹: {config.teacher_path}")
    print(f"   ä½¿ç”¨çœŸå®Qwen: {config.use_real_teacher}")
    print(f"   å­¦ç”Ÿæ¨¡å‹: {config.student_model_type}-{config.student_model_size}")
    print(f"   è’¸é¦ç±»å‹: {config.distillation_type}")
    print(f"   ç‰¹å¾æŸå¤±: {config.feature_loss_type}")
    print(f"   ç¡¬æ ‡ç­¾æƒé‡: {config.hard_label_weight}")
    print(f"   è½¯æ ‡ç­¾æƒé‡: {config.soft_label_weight}")
    print(f"   è®­ç»ƒè½®æ•°: {config.epochs}")
    print(f"   æ‰¹æ¬¡å¤§å°: {config.batch_size}")

    # æ£€æŸ¥è·¯å¾„
    print("\nğŸ” æ£€æŸ¥è·¯å¾„...")
    train_path = os.path.join(config.datasets_root, config.dataset_id, "train")
    val_path = os.path.join(config.datasets_root, config.dataset_id, "val")

    if not os.path.exists(train_path):
        print(f"âŒ é”™è¯¯: è®­ç»ƒé›†ä¸å­˜åœ¨: {train_path}")
        print(f"è¯·å…ˆè¿è¡Œ convert_cifar10.py")
        return

    if not os.path.exists(val_path):
        print(f"âŒ é”™è¯¯: éªŒè¯é›†ä¸å­˜åœ¨: {val_path}")
        return

    if config.use_real_teacher and not os.path.exists(config.teacher_path):
        print(f"âŒ é”™è¯¯: æ•™å¸ˆæ¨¡å‹ä¸å­˜åœ¨: {config.teacher_path}")
        print(f"æç¤º: å¯ä»¥è®¾ç½® use_real_teacher=False ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹å¿«é€Ÿæµ‹è¯•")
        return

    print("âœ… è·¯å¾„æ£€æŸ¥é€šè¿‡")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = DistillationTrainer(config)

    # å¼€å§‹è®­ç»ƒ
    trainer.train()

    print("\nâœ… çŸ¥è¯†è’¸é¦æµ‹è¯•å®Œæˆï¼")
    if not config.use_real_teacher:
        print("\nğŸ’¡ æç¤º: å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•™å¸ˆæ¨¡å‹")
        print("   å¦‚éœ€å®Œæ•´è’¸é¦è®­ç»ƒï¼Œè¯·è®¾ç½® use_real_teacher=True")


if __name__ == "__main__":
    main()
