#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†åŠ è½½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿæ”¯æŒçš„å„ç§æ•°æ®é›†æ ¼å¼å’ŒåŠ è½½æ–¹å¼

æ”¯æŒçš„æ•°æ®é›†ï¼š
1. CIFAR-10/100 (åˆ†ç±»)
2. ImageNetæ ¼å¼ (åˆ†ç±»)
3. COCOæ ¼å¼ (æ£€æµ‹)
4. Pascal VOCæ ¼å¼ (æ£€æµ‹/åˆ†å‰²)
5. è‡ªå®šä¹‰å›¾åƒæ–‡ä»¶å¤¹

ä½œè€…ï¼šClaude Assistant
æ—¥æœŸï¼š2026-01-14
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
from PIL import Image
from pathlib import Path
import json
import sys

print("=" * 70)
print("ğŸ“¦ æ•°æ®é›†åŠ è½½æµ‹è¯•")
print("=" * 70)
print()

# ==================== æµ‹è¯•1: CIFAR-10 ====================
print("ğŸ“Œ æµ‹è¯•1: CIFAR-10 æ•°æ®é›†")
print("-" * 70)

dataset_root = Path("./datasets")
dataset_root.mkdir(exist_ok=True)

try:
    # æ•°æ®å¢å¼º
    transform = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    # åŠ è½½è®­ç»ƒé›†
    trainset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=True,
        download=True,
        transform=transform
    )

    # åŠ è½½æµ‹è¯•é›†
    testset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=False,
        download=True,
        transform=transform
    )

    print(f"âœ… CIFAR-10 åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé›†: {len(trainset)} å¼ ")
    print(f"   æµ‹è¯•é›†: {len(testset)} å¼ ")
    print(f"   ç±»åˆ«æ•°: {len(trainset.classes)}")
    print(f"   ç±»åˆ«å: {trainset.classes}")

    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)
    images, labels = next(iter(trainloader))
    print(f"   æ‰¹æ¬¡å½¢çŠ¶: {images.shape} (NCHW)")
    print(f"   æ ‡ç­¾å½¢çŠ¶: {labels.shape}")

except Exception as e:
    print(f"âŒ CIFAR-10 åŠ è½½å¤±è´¥: {e}")

print()

# ==================== æµ‹è¯•2: CIFAR-100 ====================
print("ğŸ“Œ æµ‹è¯•2: CIFAR-100 æ•°æ®é›†")
print("-" * 70)

try:
    trainset = torchvision.datasets.CIFAR100(
        root=str(dataset_root),
        train=True,
        download=True,
        transform=transform
    )

    print(f"âœ… CIFAR-100 åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé›†: {len(trainset)} å¼ ")
    print(f"   ç±»åˆ«æ•°: {len(trainset.classes)}")
    print(f"   å‰10ä¸ªç±»: {trainset.classes[:10]}")

except Exception as e:
    print(f"âŒ CIFAR-100 åŠ è½½å¤±è´¥: {e}")

print()

# ==================== æµ‹è¯•3: ImageNetæ ¼å¼ ====================
print("ğŸ“Œ æµ‹è¯•3: ImageNetæ ¼å¼æ•°æ®é›†")
print("-" * 70)

imagenet_path = Path("/home/user/datasets/imagenet")
if imagenet_path.exists():
    try:
        transform_imagenet = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225]),
        ])

        dataset = torchvision.datasets.ImageFolder(
            root=str(imagenet_path / "train"),
            transform=transform_imagenet
        )

        print(f"âœ… ImageNetæ ¼å¼æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   å›¾ç‰‡æ•°é‡: {len(dataset)}")
        print(f"   ç±»åˆ«æ•°é‡: {len(dataset.classes)}")
        print(f"   å‰5ä¸ªç±»: {dataset.classes[:5]}")

    except Exception as e:
        print(f"âš ï¸  ImageNetåŠ è½½å¤±è´¥: {e}")
else:
    print(f"âš ï¸  ImageNetè·¯å¾„ä¸å­˜åœ¨: {imagenet_path}")
    print(f"   å¦‚æœæœ‰ImageNetæ•°æ®é›†ï¼Œè¯·æ”¾åœ¨: /home/user/datasets/imagenet/")
    print(f"   ç›®å½•ç»“æ„: imagenet/train/class_name/*.jpg")

print()

# ==================== æµ‹è¯•4: è‡ªå®šä¹‰å›¾åƒæ–‡ä»¶å¤¹ ====================
print("ğŸ“Œ æµ‹è¯•4: è‡ªå®šä¹‰å›¾åƒæ–‡ä»¶å¤¹")
print("-" * 70)

class CustomImageDataset(Dataset):
    """è‡ªå®šä¹‰å›¾åƒæ•°æ®é›†ï¼ˆæ¼”ç¤ºï¼‰"""

    def __init__(self, root_dir, transform=None):
        self.root_dir = Path(root_dir)
        self.transform = transform

        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']

        # æ‰«ææ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        self.classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}

        # æ”¶é›†æ‰€æœ‰å›¾åƒè·¯å¾„
        self.samples = []
        for cls_name in self.classes:
            cls_dir = self.root_dir / cls_name
            for img_path in cls_dir.iterdir():
                if img_path.suffix.lower() in self.image_extensions:
                    self.samples.append((str(img_path), self.class_to_idx[cls_name]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label


# ç¤ºä¾‹ï¼šæ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰æ•°æ®é›†
custom_dataset_path = Path("/home/user/datasets/custom_images")
if custom_dataset_path.exists():
    try:
        transform_custom = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

        dataset = CustomImageDataset(
            root_dir=custom_dataset_path,
            transform=transform_custom
        )

        print(f"âœ… è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   å›¾ç‰‡æ•°é‡: {len(dataset)}")
        print(f"   ç±»åˆ«æ•°é‡: {len(dataset.classes)}")
        print(f"   ç±»åˆ«: {dataset.classes}")

    except Exception as e:
        print(f"âš ï¸  è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
else:
    print(f"âš ï¸  è‡ªå®šä¹‰æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {custom_dataset_path}")
    print(f"   è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼ç¤ºä¾‹:")
    print(f"   /home/user/datasets/custom_images/")
    print(f"     â”œâ”€â”€ class_1/")
    print(f"     â”‚   â”œâ”€â”€ img1.jpg")
    print(f"     â”‚   â””â”€â”€ img2.jpg")
    print(f"     â””â”€â”€ class_2/")
    print(f"         â”œâ”€â”€ img3.jpg")
    print(f"         â””â”€â”€ img4.jpg")

print()

# ==================== æµ‹è¯•5: COCOæ ¼å¼ ====================
print("ğŸ“Œ æµ‹è¯•5: COCOæ ¼å¼ï¼ˆç›®æ ‡æ£€æµ‹ï¼‰")
print("-" * 70)

coco_path = Path("/home/user/datasets/coco")
if (coco_path / "annotations").exists():
    try:
        # å°è¯•åŠ è½½COCOæ•°æ®é›†
        from pycocotools.coco import COCO

        ann_file = coco_path / "annotations" / "instances_train2017.json"
        if ann_file.exists():
            coco = COCO(str(ann_file))

            # è·å–ç±»åˆ«ä¿¡æ¯
            cats = coco.loadCats(coco.getCatIds())
            cat_names = [cat['name'] for cat in cats]

            print(f"âœ… COCOæ•°æ®é›†åŠ è½½æˆåŠŸ")
            print(f"   ç±»åˆ«æ•°: {len(cat_names)}")
            print(f"   å‰10ä¸ªç±»: {cat_names[:10]}")
            print(f"   å›¾ç‰‡æ•°: {len(coco.getImgIds())}")
        else:
            print(f"âš ï¸  COCOæ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {ann_file}")

    except ImportError:
        print(f"âš ï¸  pycocotoolsæœªå®‰è£…")
        print(f"   å®‰è£…å‘½ä»¤: pip install pycocotools")
    except Exception as e:
        print(f"âš ï¸  COCOåŠ è½½å¤±è´¥: {e}")
else:
    print(f"âš ï¸  COCOæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {coco_path}")
    print(f"   COCOæ•°æ®é›†ä¸‹è½½: https://cocodataset.org/")
    print(f"   ç›®å½•ç»“æ„:")
    print(f"     coco/")
    print(f"       â”œâ”€â”€ annotations/")
    print(f"       â”‚   â””â”€â”€ instances_train2017.json")
    print(f"       â””â”€â”€ train2017/")
    print(f"           â””â”€â”€ *.jpg")

print()

# ==================== æµ‹è¯•6: Pascal VOCæ ¼å¼ ====================
print("ğŸ“Œ æµ‹è¯•6: Pascal VOCæ ¼å¼")
print("-" * 70)

voc_path = Path("/home/user/datasets/VOCdevkit")
if voc_path.exists():
    try:
        dataset = torchvision.datasets.VOCDetection(
            root=str(voc_path.parent),
            year='2012',
            image_set='train',
            download=False
        )

        print(f"âœ… Pascal VOCåŠ è½½æˆåŠŸ")
        print(f"   å›¾ç‰‡æ•°é‡: {len(dataset)}")

    except Exception as e:
        print(f"âš ï¸  Pascal VOCåŠ è½½å¤±è´¥: {e}")
else:
    print(f"âš ï¸  Pascal VOCè·¯å¾„ä¸å­˜åœ¨: {voc_path}")
    print(f"   ç›®å½•ç»“æ„:")
    print(f"     VOCdevkit/")
    print(f"       â””â”€â”€ VOC2012/")
    print(f"           â”œâ”€â”€ Annotations/")
    print(f"           â”œâ”€â”€ ImageSets/")
    print(f"           â””â”€â”€ JPEGImages/")

print()

# ==================== æµ‹è¯•7: æ•°æ®å¢å¼ºæ•ˆæœ ====================
print("ğŸ“Œ æµ‹è¯•7: æ•°æ®å¢å¼ºæ•ˆæœ")
print("-" * 70)

try:
    # å®šä¹‰å¤šç§æ•°æ®å¢å¼º
    augmentations = {
        "åŸºç¡€å¢å¼º": transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
        ]),
        "å¼ºå¢å¼º": transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.ToTensor(),
        ]),
        "æœ€å°å¢å¼º": transforms.Compose([
            transforms.ToTensor(),
        ]),
    }

    # ä½¿ç”¨CIFAR-10æµ‹è¯•
    for aug_name, transform in augmentations.items():
        dataset = torchvision.datasets.CIFAR10(
            root=str(dataset_root),
            train=True,
            download=False,
            transform=transform
        )
        print(f"âœ… {aug_name:15s} | æ•°æ®é›†å¤§å°: {len(dataset)}")

except Exception as e:
    print(f"âŒ æ•°æ®å¢å¼ºæµ‹è¯•å¤±è´¥: {e}")

print()

# ==================== æµ‹è¯•8: DataLoaderæ€§èƒ½ ====================
print("ğŸ“Œ æµ‹è¯•8: DataLoaderæ€§èƒ½æµ‹è¯•")
print("-" * 70)

try:
    import time

    dataset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=True,
        download=False,
        transform=transform
    )

    # æµ‹è¯•ä¸åŒnum_workers
    for num_workers in [0, 2, 4]:
        loader = DataLoader(
            dataset,
            batch_size=128,
            shuffle=True,
            num_workers=num_workers
        )

        start_time = time.time()
        for i, (images, labels) in enumerate(loader):
            if i >= 10:  # åªæµ‹è¯•10ä¸ªbatch
                break
        elapsed = time.time() - start_time

        print(f"âœ… num_workers={num_workers} | åŠ è½½10ä¸ªbatchç”¨æ—¶: {elapsed:.3f}ç§’")

except Exception as e:
    print(f"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}")

print()

# ==================== æ€»ç»“ ====================
print("=" * 70)
print("ğŸ“Š æ•°æ®é›†æµ‹è¯•æ€»ç»“")
print("=" * 70)
print()

print("âœ… å·²éªŒè¯çš„æ•°æ®é›†:")
print("   - CIFAR-10/100 (å†…ç½®ï¼Œè‡ªåŠ¨ä¸‹è½½)")
print()

print("ğŸ“ æ•°æ®é›†å‡†å¤‡å»ºè®®:")
print()
print("   1. å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰:")
print("      - ä½¿ç”¨CIFAR-10ï¼ˆ50,000è®­ç»ƒ+10,000æµ‹è¯•ï¼Œ32x32ï¼‰")
print("      - è‡ªåŠ¨ä¸‹è½½ï¼Œæ— éœ€æ‰‹åŠ¨å‡†å¤‡")
print("      - é€‚åˆéªŒè¯è®­ç»ƒæµç¨‹")
print()

print("   2. å®é™…åº”ç”¨:")
print("      - åˆ†ç±»ä»»åŠ¡: å‡†å¤‡ImageNetæ ¼å¼æ•°æ®é›†")
print("      - æ£€æµ‹ä»»åŠ¡: å‡†å¤‡COCOæˆ–VOCæ ¼å¼")
print("      - åˆ†å‰²ä»»åŠ¡: å‡†å¤‡å¸¦maskçš„æ•°æ®é›†")
print()

print("   3. è‡ªå®šä¹‰æ•°æ®é›†:")
print("      - åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„: dataset_name/class_name/*.jpg")
print("      - ç¡®ä¿å›¾ç‰‡æ ¼å¼ç»Ÿä¸€ï¼ˆJPG/PNGï¼‰")
print("      - æ¯ä¸ªç±»åˆ«è‡³å°‘100å¼ å›¾ç‰‡ï¼ˆå»ºè®®ï¼‰")
print()

print("ğŸ’¡ æ¨èçš„æ•°æ®é›†é…ç½®:")
print()
print("   è®­ç»ƒé˜¶æ®µ:")
print("   - Batch Size: 32-64 (æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´)")
print("   - Num Workers: 2-4 (æ ¹æ®CPUæ ¸å¿ƒæ•°)")
print("   - Shuffle: True")
print("   - æ•°æ®å¢å¼º: éšæœºè£å‰ªã€ç¿»è½¬ã€å½’ä¸€åŒ–")
print()

print("   éªŒè¯é˜¶æ®µ:")
print("   - Batch Size: 64-128")
print("   - Shuffle: False")
print("   - æ•°æ®å¢å¼º: ä»…Resizeå’Œå½’ä¸€åŒ–")
print()

print("ğŸ“ ä¸‹ä¸€æ­¥:")
print("   1. ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨çš„æ•°æ®é›†ï¼ˆCIFAR-10å·²è‡ªåŠ¨ä¸‹è½½ï¼‰")
print("   2. è¿è¡Œç¯å¢ƒæµ‹è¯•: python test_environment.py")
print("   3. è¿è¡Œç®€å•è®­ç»ƒ: python test_simple_training.py")
print("   4. é…ç½®å®Œæ•´çš„è’¸é¦è®­ç»ƒä»»åŠ¡")
print()

print("=" * 70)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
