#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pythonç¯å¢ƒæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯å¤§å°æ¨¡å‹ååŒè®­ç»ƒç³»ç»Ÿçš„Pythonç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®

æµ‹è¯•é¡¹ç›®ï¼š
1. Pythonç‰ˆæœ¬
2. PyTorchå’ŒCUDA
3. å¿…éœ€ä¾èµ–åŒ…
4. å¯é€‰ä¾èµ–åŒ…
5. æ¨¡å‹åŠ è½½èƒ½åŠ›
6. æ•°æ®é›†è®¿é—®

ä½œè€…ï¼šClaude Assistant
æ—¥æœŸï¼š2026-01-14
"""

import sys
import os
from pathlib import Path

print("=" * 70)
print("ğŸ” å¤§å°æ¨¡å‹ååŒè®­ç»ƒç³»ç»Ÿ - Pythonç¯å¢ƒæµ‹è¯•")
print("=" * 70)
print()

# ==================== æµ‹è¯•1: Pythonç‰ˆæœ¬ ====================
print("ğŸ“Œ æµ‹è¯•1: Pythonç‰ˆæœ¬")
print("-" * 70)
print(f"Pythonç‰ˆæœ¬: {sys.version}")
print(f"Pythonè·¯å¾„: {sys.executable}")

py_version = sys.version_info
if py_version >= (3, 8):
    print("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 3.8)")
else:
    print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ >= 3.8ï¼Œå½“å‰: {py_version.major}.{py_version.minor}")
    sys.exit(1)
print()

# ==================== æµ‹è¯•2: PyTorch ====================
print("ğŸ“Œ æµ‹è¯•2: PyTorch")
print("-" * 70)
try:
    import torch
    print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   å®‰è£…è·¯å¾„: {torch.__file__}")

    # æµ‹è¯•CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨")
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
            # æ˜¾å­˜ä¿¡æ¯
            total_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"        æ˜¾å­˜: {total_memory:.2f} GB")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
        print("   å¦‚æœæœ‰NVIDIA GPUï¼Œè¯·å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch")
        print("   å‚è€ƒ: https://pytorch.org/get-started/locally/")
except ImportError as e:
    print(f"âŒ PyTorchæœªå®‰è£…: {e}")
    print("   å®‰è£…å‘½ä»¤: pip install torch torchvision")
    sys.exit(1)
print()

# ==================== æµ‹è¯•3: TorchVision ====================
print("ğŸ“Œ æµ‹è¯•3: TorchVision")
print("-" * 70)
try:
    import torchvision
    print(f"âœ… TorchVisionç‰ˆæœ¬: {torchvision.__version__}")
except ImportError:
    print("âŒ TorchVisionæœªå®‰è£…")
    print("   å®‰è£…å‘½ä»¤: pip install torchvision")
print()

# ==================== æµ‹è¯•4: Transformers ====================
print("ğŸ“Œ æµ‹è¯•4: Transformers (Hugging Face)")
print("-" * 70)
try:
    import transformers
    print(f"âœ… Transformersç‰ˆæœ¬: {transformers.__version__}")

    # æµ‹è¯•AutoProcessorå’ŒAutoModel
    try:
        from transformers import AutoProcessor, AutoModelForImageClassification
        print("âœ… AutoProcessorå’ŒAutoModelå¯ç”¨")
    except ImportError as e:
        print(f"âš ï¸  éƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨: {e}")
except ImportError:
    print("âŒ Transformersæœªå®‰è£…")
    print("   å®‰è£…å‘½ä»¤: pip install transformers")
    print("   ç”¨é€”: ç”¨äºViTç­‰Transformeræ¨¡å‹")
print()

# ==================== æµ‹è¯•5: PEFT (LoRA) ====================
print("ğŸ“Œ æµ‹è¯•5: PEFT (LoRAæ”¯æŒ)")
print("-" * 70)
try:
    import peft
    print(f"âœ… PEFTç‰ˆæœ¬: {peft.__version__}")
    from peft import LoraConfig, get_peft_model
    print("âœ… LoRAé…ç½®å¯ç”¨")
except ImportError:
    print("âŒ PEFTæœªå®‰è£…")
    print("   å®‰è£…å‘½ä»¤: pip install peft")
    print("   ç”¨é€”: ç”¨äºLoRAé«˜æ•ˆå¾®è°ƒ")
print()

# ==================== æµ‹è¯•6: YOLOv8 ====================
print("ğŸ“Œ æµ‹è¯•6: YOLOv8 (Ultralytics)")
print("-" * 70)
try:
    from ultralytics import YOLO
    print(f"âœ… Ultralyticså¯ç”¨")
    # å°è¯•åˆ—å‡ºYOLOç‰ˆæœ¬
    import ultralytics
    print(f"   ç‰ˆæœ¬: {ultralytics.__version__}")
except ImportError:
    print("âš ï¸  YOLOv8æœªå®‰è£…ï¼ˆå¦‚æœéœ€è¦ç›®æ ‡æ£€æµ‹ä»»åŠ¡æ‰éœ€è¦ï¼‰")
    print("   å®‰è£…å‘½ä»¤: pip install ultralytics")
print()

# ==================== æµ‹è¯•7: å…¶ä»–ä¾èµ–åŒ… ====================
print("ğŸ“Œ æµ‹è¯•7: å…¶ä»–å¿…éœ€ä¾èµ–")
print("-" * 70)

required_packages = {
    'numpy': 'æ•°å€¼è®¡ç®—',
    'pandas': 'æ•°æ®å¤„ç†',
    'Pillow': 'å›¾åƒå¤„ç†',
    'tqdm': 'è¿›åº¦æ¡',
    'requests': 'HTTPè¯·æ±‚',
    'scikit-learn': 'æœºå™¨å­¦ä¹ å·¥å…·'
}

for package, description in required_packages.items():
    try:
        module = __import__(package.replace('-', '_').lower())
        version = getattr(module, '__version__', 'unknown')
        print(f"âœ… {package:20s} {version:15s} - {description}")
    except ImportError:
        print(f"âš ï¸  {package:20s} {'æœªå®‰è£…':15s} - {description}")
print()

# ==================== æµ‹è¯•8: å¯é€‰ä¾èµ–åŒ… ====================
print("ğŸ“Œ æµ‹è¯•8: å¯é€‰ä¾èµ–åŒ…")
print("-" * 70)

optional_packages = {
    'matplotlib': 'æ•°æ®å¯è§†åŒ–',
    'seaborn': 'é«˜çº§å¯è§†åŒ–',
    'timm': 'æ›´å¤šé¢„è®­ç»ƒæ¨¡å‹',
    'segmentation_models_pytorch': 'UNetç­‰åˆ†å‰²æ¨¡å‹',
    'accelerate': 'æ¨¡å‹åŠ é€Ÿ',
}

for package, description in optional_packages.items():
    try:
        module = __import__(package.replace('-', '_'))
        version = getattr(module, '__version__', 'unknown')
        print(f"âœ… {package:30s} {version:15s} - {description}")
    except ImportError:
        print(f"âš ï¸  {package:30s} {'æœªå®‰è£…':15s} - {description}")
print()

# ==================== æµ‹è¯•9: ç®€å•çš„å¼ é‡æ“ä½œ ====================
print("ğŸ“Œ æµ‹è¯•9: PyTorchå¼ é‡æ“ä½œ")
print("-" * 70)
try:
    # CPUæµ‹è¯•
    x = torch.randn(3, 3)
    y = torch.randn(3, 3)
    z = torch.matmul(x, y)
    print(f"âœ… CPUå¼ é‡è¿ç®—æ­£å¸¸")

    # GPUæµ‹è¯•
    if torch.cuda.is_available():
        x_gpu = x.cuda()
        y_gpu = y.cuda()
        z_gpu = torch.matmul(x_gpu, y_gpu)
        print(f"âœ… GPUå¼ é‡è¿ç®—æ­£å¸¸")
        print(f"   ç»“æœå½¢çŠ¶: {z_gpu.shape}")
except Exception as e:
    print(f"âŒ å¼ é‡è¿ç®—å¤±è´¥: {e}")
print()

# ==================== æµ‹è¯•10: é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æµ‹è¯• ====================
print("ğŸ“Œ æµ‹è¯•10: é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æµ‹è¯•")
print("-" * 70)
try:
    # æµ‹è¯•ResNetï¼ˆè½»é‡çº§ï¼‰
    print("æµ‹è¯•ResNet18...")
    import torchvision.models as models
    model = models.resnet18(pretrained=False)  # ä¸ä¸‹è½½æƒé‡ï¼Œåªæµ‹è¯•ç»“æ„
    print(f"âœ… ResNet18ç»“æ„åŠ è½½æˆåŠŸ")
    print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # å¦‚æœæœ‰GPUï¼Œæµ‹è¯•ç§»åŠ¨åˆ°GPU
    if torch.cuda.is_available():
        model = model.cuda()
        print(f"âœ… æ¨¡å‹æˆåŠŸç§»åŠ¨åˆ°GPU")

        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_input = torch.randn(1, 3, 224, 224).cuda()
        with torch.no_grad():
            output = model(dummy_input)
        print(f"âœ… GPUå‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
except Exception as e:
    print(f"âš ï¸  æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
print()

# ==================== æµ‹è¯•11: æ•°æ®é›†è®¿é—®æµ‹è¯• ====================
print("ğŸ“Œ æµ‹è¯•11: æ•°æ®é›†è·¯å¾„æ£€æŸ¥")
print("-" * 70)

dataset_root = Path("/home/user/datasets")
if dataset_root.exists():
    print(f"âœ… æ•°æ®é›†æ ¹ç›®å½•å­˜åœ¨: {dataset_root}")
    # åˆ—å‡ºå­ç›®å½•
    subdirs = [d for d in dataset_root.iterdir() if d.is_dir()]
    if subdirs:
        print(f"   æ‰¾åˆ° {len(subdirs)} ä¸ªæ•°æ®é›†ç›®å½•:")
        for d in subdirs[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            print(f"   - {d.name}")
        if len(subdirs) > 5:
            print(f"   ... è¿˜æœ‰ {len(subdirs) - 5} ä¸ª")
    else:
        print(f"   âš ï¸  ç›®å½•ä¸ºç©ºï¼Œè¯·æ·»åŠ æ•°æ®é›†")
else:
    print(f"âš ï¸  æ•°æ®é›†æ ¹ç›®å½•ä¸å­˜åœ¨: {dataset_root}")
    print(f"   è¯·åˆ›å»ºç›®å½•: mkdir -p {dataset_root}")
print()

# ==================== æµ‹è¯•12: æ¨¡å‹è·¯å¾„æ£€æŸ¥ ====================
print("ğŸ“Œ æµ‹è¯•12: æ¨¡å‹è·¯å¾„æ£€æŸ¥")
print("-" * 70)

models_root = Path("/home/user/models")
if models_root.exists():
    print(f"âœ… æ¨¡å‹æ ¹ç›®å½•å­˜åœ¨: {models_root}")
    # æ£€æŸ¥Qwen2.5-VL
    qwen_path = models_root / "qwen2.5-vl-8b"
    if qwen_path.exists():
        print(f"âœ… Qwen2.5-VLæ¨¡å‹è·¯å¾„å­˜åœ¨: {qwen_path}")
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        required_files = ['config.json', 'pytorch_model.bin', 'tokenizer_config.json']
        for f in required_files:
            if (qwen_path / f).exists():
                print(f"   âœ… {f}")
            else:
                print(f"   âš ï¸  ç¼ºå°‘ {f}")
    else:
        print(f"âš ï¸  Qwen2.5-VLæ¨¡å‹æœªæ‰¾åˆ°: {qwen_path}")
        print(f"   è¯·ä¸‹è½½æ¨¡å‹æˆ–ä¿®æ”¹é…ç½®")
else:
    print(f"âš ï¸  æ¨¡å‹æ ¹ç›®å½•ä¸å­˜åœ¨: {models_root}")
    print(f"   è¯·åˆ›å»ºç›®å½•: mkdir -p {models_root}")
print()

# ==================== æ€»ç»“ ====================
print("=" * 70)
print("ğŸ“Š æµ‹è¯•æ€»ç»“")
print("=" * 70)
print()

print("âœ… å¿…éœ€ç»„ä»¶:")
print("   - Python >= 3.8")
print("   - PyTorch")
print("   - TorchVision")
print()

print("âš ï¸  å¯é€‰ç»„ä»¶ï¼ˆæ ¹æ®éœ€è¦å®‰è£…ï¼‰:")
print("   - Transformers (ç”¨äºViTã€Qwen2.5-VL)")
print("   - PEFT (ç”¨äºLoRA)")
print("   - Ultralytics (ç”¨äºYOLOv8)")
print("   - CUDA (ç”¨äºGPUåŠ é€Ÿ)")
print()

print("ğŸ“ ä¸‹ä¸€æ­¥å»ºè®®:")
if not torch.cuda.is_available():
    print("   1. å¦‚æœæœ‰NVIDIA GPUï¼Œå®‰è£…CUDAç‰ˆæœ¬çš„PyTorch")
print("   2. å‡†å¤‡æ•°æ®é›†åˆ° /home/user/datasets/")
print("   3. ï¼ˆå¯é€‰ï¼‰ä¸‹è½½Qwen2.5-VLæ¨¡å‹åˆ° /home/user/models/")
print("   4. è¿è¡Œç®€å•è®­ç»ƒæµ‹è¯•: python test_simple_training.py")
print()

print("=" * 70)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
