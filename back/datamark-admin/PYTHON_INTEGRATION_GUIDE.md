# Pythonè®­ç»ƒçŽ¯å¢ƒé›†æˆæŒ‡å—

## ðŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæž¶æž„](#ç³»ç»Ÿæž¶æž„)
2. [PythonçŽ¯å¢ƒé…ç½®](#pythonçŽ¯å¢ƒé…ç½®)
3. [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
4. [é…ç½®è¯´æ˜Ž](#é…ç½®è¯´æ˜Ž)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ðŸ—ï¸ ç³»ç»Ÿæž¶æž„

### æ•´ä½“æž¶æž„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚         â”‚                  â”‚         â”‚                 â”‚
â”‚  Vue 3å‰ç«¯  â”‚ â”€â”€HTTPâ”€â–¶â”‚  Spring BootåŽç«¯ â”‚ â”€â”€å¯åŠ¨â”€â–¶â”‚  Pythonè®­ç»ƒè¿›ç¨‹ â”‚
â”‚             â”‚         â”‚                  â”‚         â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                         â”‚                             â”‚
      â”‚                         â”‚                             â”‚
      â”‚                    æ“ä½œæ•°æ®åº“                      è¯»å†™æ¨¡åž‹/æ•°æ®
      â”‚                         â”‚                             â”‚
      â–¼                         â–¼                             â–¼
 WebSocketå®žæ—¶          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   æŽ¨é€è¿›åº¦             â”‚   MySQL     â”‚              â”‚  æ–‡ä»¶ç³»ç»Ÿ    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ /home/user/  â”‚
                                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

1. **å‰ç«¯ï¼ˆVue 3ï¼‰**
   - ç”¨æˆ·ç•Œé¢ï¼šåˆ›å»ºè®­ç»ƒä»»åŠ¡ã€é…ç½®å‚æ•°
   - å®žæ—¶ç›‘æŽ§ï¼šæ˜¾ç¤ºè®­ç»ƒè¿›åº¦ã€Lossã€Accuracy
   - æ–‡ä»¶è·¯å¾„ï¼š`/home/user/work/front/data-mark-v3/`

2. **åŽç«¯ï¼ˆSpring Bootï¼‰**
   - APIæŽ¥å£ï¼šæŽ¥æ”¶å‰ç«¯è¯·æ±‚
   - è®­ç»ƒç®¡ç†ï¼š`DistillationTrainingManager.java`
   - è¿›ç¨‹æŽ§åˆ¶ï¼šå¯åŠ¨/åœæ­¢/æš‚åœPythonè¿›ç¨‹
   - æ–‡ä»¶è·¯å¾„ï¼š`/home/user/work/back/datamark-admin/`

3. **Pythonè®­ç»ƒè„šæœ¬**
   - å®žé™…è®­ç»ƒé€»è¾‘ï¼šçŸ¥è¯†è’¸é¦ç®—æ³•
   - æ¨¡åž‹åŠ è½½ï¼šæ•™å¸ˆæ¨¡åž‹ã€å­¦ç”Ÿæ¨¡åž‹
   - æ•°æ®å¤„ç†ï¼šæ•°æ®é›†åŠ è½½ã€å¢žå¼º
   - æ–‡ä»¶è·¯å¾„ï¼š`/home/user/work/back/datamark-admin/python_scripts/`

---

## ðŸ PythonçŽ¯å¢ƒé…ç½®

### æ–¹å¼1: ä½¿ç”¨ç³»ç»ŸPythonï¼ˆç®€å•ä½†ä¸æŽ¨èï¼‰

```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python3 --version  # éœ€è¦ >= 3.8

# å…¨å±€å®‰è£…ä¾èµ–ï¼ˆéœ€è¦rootæƒé™ï¼‰
sudo pip3 install torch torchvision transformers peft ultralytics

# é…ç½®æ–‡ä»¶ï¼šapplication-distillation.yml
training:
  python:
    executable: python3
```

**ä¼˜ç‚¹**: é…ç½®ç®€å•
**ç¼ºç‚¹**:
- éœ€è¦rootæƒé™
- å¯èƒ½ä¸Žç³»ç»Ÿå…¶ä»–Pythoné¡¹ç›®å†²çª
- éš¾ä»¥ç®¡ç†ä¾èµ–ç‰ˆæœ¬

---

### æ–¹å¼2: ä½¿ç”¨Pythonè™šæ‹ŸçŽ¯å¢ƒï¼ˆæŽ¨èâ­ï¼‰

#### æ­¥éª¤1: åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ

```bash
cd /home/user/work/back/datamark-admin

# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
python3 -m venv venv

# æŸ¥çœ‹åˆ›å»ºç»“æžœ
ls -la venv/
# åº”è¯¥çœ‹åˆ°: bin/  include/  lib/  pyvenv.cfg
```

#### æ­¥éª¤2: æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒå¹¶å®‰è£…ä¾èµ–

```bash
# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source venv/bin/activate

# ä½ ä¼šçœ‹åˆ°å‘½ä»¤è¡Œå‰ç¼€å˜ä¸º: (venv)

# å‡çº§pip
pip install --upgrade pip

# å®‰è£…PyTorchï¼ˆCUDAç‰ˆæœ¬ï¼Œæ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers>=4.37.0
pip install peft>=0.7.0
pip install ultralytics>=8.0.0
pip install pillow
pip install numpy
pip install matplotlib

# ä¿å­˜ä¾èµ–åˆ—è¡¨ï¼ˆæ–¹ä¾¿å…¶ä»–äººå®‰è£…ï¼‰
pip freeze > requirements.txt

# é€€å‡ºè™šæ‹ŸçŽ¯å¢ƒ
deactivate
```

#### æ­¥éª¤3: é…ç½®Spring Bootä½¿ç”¨è™šæ‹ŸçŽ¯å¢ƒ

ç¼–è¾‘ `application-dev.yml` æˆ– `application.yml`ï¼š

```yaml
training:
  python:
    # æ–¹å¼A: ç›´æŽ¥æŒ‡å®šè™šæ‹ŸçŽ¯å¢ƒä¸­çš„python
    executable: /home/user/work/back/datamark-admin/venv/bin/python

    # æ–¹å¼B: é…ç½®è™šæ‹ŸçŽ¯å¢ƒè·¯å¾„ï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨venv/bin/python
    venv-path: /home/user/work/back/datamark-admin/venv
```

**ä¼˜ç‚¹**:
- âœ… çŽ¯å¢ƒéš”ç¦»ï¼Œä¸å½±å“ç³»ç»ŸPython
- âœ… ä¾èµ–ç®¡ç†æ¸…æ™°
- âœ… å¯ä»¥ç²¾ç¡®æŽ§åˆ¶ç‰ˆæœ¬
- âœ… ä¸éœ€è¦rootæƒé™

**è¿™æ˜¯ç”Ÿäº§çŽ¯å¢ƒæŽ¨èçš„æ–¹å¼ï¼**

---

### æ–¹å¼3: ä½¿ç”¨CondaçŽ¯å¢ƒ

```bash
# åˆ›å»ºcondaçŽ¯å¢ƒ
conda create -n distillation python=3.10

# æ¿€æ´»çŽ¯å¢ƒ
conda activate distillation

# å®‰è£…ä¾èµ–
conda install pytorch torchvision -c pytorch
conda install transformers -c huggingface
pip install peft ultralytics

# æŸ¥çœ‹pythonè·¯å¾„
which python
# ä¾‹å¦‚: /home/user/anaconda3/envs/distillation/bin/python

# é…ç½®
training:
  python:
    executable: /home/user/anaconda3/envs/distillation/bin/python
```

---

## ðŸš€ è®­ç»ƒæµç¨‹

### å®Œæ•´æµç¨‹å›¾

```
1. å‰ç«¯ï¼šç”¨æˆ·ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"
         â†“
2. å‰ç«¯ï¼šå‘é€POSTè¯·æ±‚åˆ°åŽç«¯
   POST /api/distillation/training/start
   {
     "teacherModel": "qwen2.5-vl-3b",
     "studentModel": "resnet18",
     "dataset": "cifar10",
     "batchSize": 32,
     ...
   }
         â†“
3. åŽç«¯ï¼šControlleræŽ¥æ”¶è¯·æ±‚
   DistillationTrainingController.startTraining()
         â†“
4. åŽç«¯ï¼šServiceå¤„ç†ä¸šåŠ¡é€»è¾‘
   - éªŒè¯å‚æ•°
   - ä¿å­˜ä»»åŠ¡åˆ°æ•°æ®åº“ï¼ˆçŠ¶æ€ï¼šPENDINGï¼‰
   - è°ƒç”¨TrainingManager
         â†“
5. åŽç«¯ï¼šDistillationTrainingManagerå¯åŠ¨Pythonè¿›ç¨‹
   - æž„å»ºå‘½ä»¤: python3 distillation_train.py --task-id xxx ...
   - ProcessBuilder.start()
   - å¼‚æ­¥è¯»å–è¾“å‡º
   - æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼šRUNNING
         â†“
6. Pythonï¼šè®­ç»ƒè„šæœ¬æ‰§è¡Œ
   - åŠ è½½æ•™å¸ˆæ¨¡åž‹ï¼ˆQwen2.5-VLï¼‰
   - åŠ è½½å­¦ç”Ÿæ¨¡åž‹ï¼ˆResNet18ï¼‰
   - åŠ è½½æ•°æ®é›†ï¼ˆCIFAR-10ï¼‰
   - å¼€å§‹è®­ç»ƒå¾ªçŽ¯
   - æ¯ä¸ªepochè¾“å‡ºï¼šEpoch 1/50, Loss: 2.345, Acc: 65.2%
         â†“
7. åŽç«¯ï¼šå®žæ—¶è¯»å–Pythonè¾“å‡º
   - è§£æžè®­ç»ƒæŒ‡æ ‡
   - æ›´æ–°æ•°æ®åº“
   - é€šè¿‡WebSocketæŽ¨é€ç»™å‰ç«¯
         â†“
8. å‰ç«¯ï¼šå®žæ—¶æ˜¾ç¤º
   - æ›´æ–°è¿›åº¦æ¡
   - ç»˜åˆ¶Loss/Accuracyæ›²çº¿
   - æ˜¾ç¤ºå½“å‰epochä¿¡æ¯
         â†“
9. Pythonï¼šè®­ç»ƒå®Œæˆ
   - ä¿å­˜å­¦ç”Ÿæ¨¡åž‹
   - è¾“å‡ºæœ€ç»ˆæŒ‡æ ‡
   - é€€å‡ºè¿›ç¨‹ï¼ˆexit code 0ï¼‰
         â†“
10. åŽç«¯ï¼šæ£€æµ‹åˆ°è¿›ç¨‹ç»“æŸ
    - æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼šCOMPLETED
    - ä¿å­˜æœ€ç»ˆç»“æžœ
    - é€šçŸ¥å‰ç«¯
```

### å…³é”®ä»£ç ä½ç½®

#### 1. JavaåŽç«¯è°ƒç”¨Python

**æ–‡ä»¶**: `DistillationTrainingManager.java`

```java
public boolean startTraining(
    String taskId,
    String teacherModel,
    String studentModel,
    ...
) {
    // æž„å»ºå‘½ä»¤
    ProcessBuilder pb = new ProcessBuilder(
        pythonExecutable,           // "/path/to/venv/bin/python"
        scriptPath,                 // "python_scripts/distillation_train.py"
        "--task-id", taskId,
        "--teacher-model", teacherModel,
        "--student-model", studentModel,
        ...
    );

    // å¯åŠ¨è¿›ç¨‹
    Process process = pb.start();

    // å¼‚æ­¥è¯»å–è¾“å‡º
    new Thread(() -> {
        BufferedReader reader = new BufferedReader(
            new InputStreamReader(process.getInputStream())
        );
        String line;
        while ((line = reader.readLine()) != null) {
            log.info("[è®­ç»ƒ {}]: {}", taskId, line);
            // TODO: è§£æžå¹¶æŽ¨é€åˆ°å‰ç«¯
        }
    }).start();

    return true;
}
```

#### 2. Pythonè®­ç»ƒè„šæœ¬

**æ–‡ä»¶**: `python_scripts/distillation_train.py`

```python
import argparse
import torch

def main():
    # è§£æžå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument('--task-id', required=True)
    parser.add_argument('--teacher-model', required=True)
    parser.add_argument('--student-model', required=True)
    parser.add_argument('--dataset', required=True)
    parser.add_argument('--batch-size', type=int, default=32)
    # ... æ›´å¤šå‚æ•°
    args = parser.parse_args()

    # åŠ è½½æ¨¡åž‹å’Œæ•°æ®
    teacher = load_teacher_model(args.teacher_model)
    student = load_student_model(args.student_model)
    train_loader, test_loader = load_dataset(args.dataset)

    # è®­ç»ƒå¾ªçŽ¯
    for epoch in range(args.epochs):
        loss, acc = train_one_epoch(teacher, student, train_loader)

        # è¾“å‡ºåˆ°stdoutï¼ˆJavaä¼šè¯»å–ï¼‰
        print(f"Epoch {epoch+1}/{args.epochs}, Loss: {loss:.4f}, Acc: {acc:.2f}%")

    # ä¿å­˜æ¨¡åž‹
    torch.save(student.state_dict(), f"models/{args.task_id}_student.pth")
    print("Training completed!")

if __name__ == '__main__':
    main()
```

---

## âš™ï¸ é…ç½®è¯´æ˜Ž

### å®Œæ•´é…ç½®æ–‡ä»¶ç¤ºä¾‹

**æ–‡ä»¶**: `application-distillation.yml`

```yaml
training:
  python:
    # Pythonå¯æ‰§è¡Œæ–‡ä»¶
    executable: python3
    # æˆ–è€…ä½¿ç”¨è™šæ‹ŸçŽ¯å¢ƒ
    venv-path: /home/user/work/back/datamark-admin/venv

    # è„šæœ¬ç›®å½•
    script-dir: /home/user/work/back/datamark-admin/python_scripts
    distillation-script: distillation_train.py

  models:
    # æ•™å¸ˆæ¨¡åž‹è·¯å¾„
    teacher-model-path: /home/user/models/qwen2.5-vl-3b-instruct
    # å­¦ç”Ÿæ¨¡åž‹ä¿å­˜è·¯å¾„
    student-model-path: /home/user/work/models/students

  datasets:
    # æ•°æ®é›†æ ¹ç›®å½•
    root-path: /home/user/datasets

  gpu:
    enabled: true
    default-device: 0  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU

  hyperparameters:
    default-batch-size: 32
    default-epochs: 50
    default-learning-rate: 0.001
    default-temperature: 4.0
    default-alpha: 0.7
```

### é…ç½®ä¼˜å…ˆçº§

1. **Pythonè·¯å¾„**:
   ```
   venv-path (å¦‚æžœé…ç½®) > executable
   ```

2. **æ•°æ®é›†è·¯å¾„**:
   ```
   å…·ä½“æ•°æ®é›†è·¯å¾„ (cifar10-path) > root-path/dataset-name
   ```

3. **è¶…å‚æ•°**:
   ```
   å‰ç«¯ä¼ å…¥çš„å‚æ•° > é…ç½®æ–‡ä»¶é»˜è®¤å€¼
   ```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•éªŒè¯PythonçŽ¯å¢ƒé…ç½®æ­£ç¡®ï¼Ÿ

```bash
# æ–¹å¼1: ç›´æŽ¥è¿è¡ŒPythonè„šæœ¬
cd /home/user/work/back/datamark-admin
source venv/bin/activate  # å¦‚æžœä½¿ç”¨è™šæ‹ŸçŽ¯å¢ƒ
python3 python_scripts/distillation_train.py --help

# æ–¹å¼2: æ£€æŸ¥Javaèƒ½å¦è°ƒç”¨Python
java -cp target/classes com.qczy.distillation.manager.DistillationTrainingManager
```

### Q2: Javaæ— æ³•æ‰¾åˆ°Pythonè„šæœ¬

**é”™è¯¯**: `è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: /path/to/script.py`

**è§£å†³**:
```bash
# æ£€æŸ¥è„šæœ¬æ˜¯å¦å­˜åœ¨
ls -l /home/user/work/back/datamark-admin/python_scripts/

# æ£€æŸ¥æƒé™
chmod +x python_scripts/distillation_train.py

# ç¡®è®¤é…ç½®è·¯å¾„æ­£ç¡®
grep "script-dir" src/main/resources/application-distillation.yml
```

### Q3: Pythonè¿›ç¨‹å¯åŠ¨å¤±è´¥

**æ£€æŸ¥æ­¥éª¤**:
```bash
# 1. æ‰‹åŠ¨è¿è¡ŒPythonå‘½ä»¤
/home/user/work/venv/bin/python \
  python_scripts/distillation_train.py \
  --task-id test \
  --teacher-model qwen2.5-vl-3b \
  --student-model resnet18 \
  --dataset cifar10

# 2. æ£€æŸ¥Pythonä¾èµ–
source venv/bin/activate
pip list | grep torch
pip list | grep transformers

# 3. æ£€æŸ¥Javaæ—¥å¿—
tail -f logs/spring.log | grep "è®­ç»ƒ"
```

### Q4: GPUä¸å¯ç”¨

**æ£€æŸ¥**:
```bash
# 1. æ£€æŸ¥CUDA
nvidia-smi

# 2. æ£€æŸ¥PyTorchèƒ½å¦è¯†åˆ«GPU
python3 -c "import torch; print(torch.cuda.is_available())"

# 3. å¦‚æžœè¿”å›žFalseï¼Œé‡æ–°å®‰è£…CUDAç‰ˆPyTorch
source venv/bin/activate
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Q5: å¦‚ä½•æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼Ÿ

**æ–¹å¼1**: Spring Bootæ—¥å¿—
```bash
tail -f logs/spring.log | grep "è®­ç»ƒä»»åŠ¡"
```

**æ–¹å¼2**: è®­ç»ƒä¸“ç”¨æ—¥å¿—æ–‡ä»¶
```bash
tail -f /home/user/work/logs/training/task-xxx.log
```

**æ–¹å¼3**: å‰ç«¯å®žæ—¶æŸ¥çœ‹
- æ‰“å¼€æµè§ˆå™¨ï¼Œè¿›å…¥è®­ç»ƒä»»åŠ¡è¯¦æƒ…é¡µ
- ç‚¹å‡»"æŸ¥çœ‹æ—¥å¿—"æ ‡ç­¾

---

## ðŸŽ¯ å¿«é€Ÿå¼€å§‹

### 5åˆ†é’Ÿå®Œæˆé…ç½®

```bash
# 1. åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
cd /home/user/work/back/datamark-admin
python3 -m venv venv
source venv/bin/activate

# 2. å®‰è£…ä¾èµ–
pip install torch torchvision transformers peft ultralytics
pip freeze > requirements.txt

# 3. é…ç½®Spring Boot
cat >> src/main/resources/application-dev.yml << 'EOF'

training:
  python:
    venv-path: /home/user/work/back/datamark-admin/venv
    script-dir: /home/user/work/back/datamark-admin/python_scripts
  models:
    teacher-model-path: /home/user/models/qwen2.5-vl-3b-instruct
    student-model-path: /home/user/work/models/students
  datasets:
    root-path: /home/user/datasets
EOF

# 4. åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p python_scripts
mkdir -p /home/user/work/models/students
mkdir -p /home/user/datasets

# 5. å¤åˆ¶è®­ç»ƒè„šæœ¬ï¼ˆä»Žæµ‹è¯•è„šæœ¬ä¿®æ”¹ï¼‰
cp test_distillation_qwen.py python_scripts/distillation_train.py

# 6. å¯åŠ¨åŽç«¯
mvn spring-boot:run

# 7. æ‰“å¼€å‰ç«¯ï¼Œåˆ›å»ºè®­ç»ƒä»»åŠ¡
```

---

## ðŸ“š ç›¸å…³æ–‡æ¡£

- [æµ‹è¯•è„šæœ¬ä½¿ç”¨æŒ‡å—](README_TESTING.md)
- [Qwen2.5-VLè’¸é¦æŒ‡å—](QWEN_DISTILLATION_GUIDE.md)
- [å®Œæ•´éƒ¨ç½²æŒ‡å—](../../COMPLETE_DEPLOYMENT_GUIDE.md)

---

**çŽ°åœ¨ä½ å·²ç»äº†è§£äº†æ•´ä¸ªPythoné›†æˆæž¶æž„ï¼** ðŸŽ‰
