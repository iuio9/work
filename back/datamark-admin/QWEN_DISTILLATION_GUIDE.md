# Qwen2.5-VLçŸ¥è¯†è’¸é¦å¿«é€ŸæŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©ä½ ä½¿ç”¨**çœŸå®çš„å¤§æ¨¡å‹ï¼ˆQwen2.5-VLï¼‰**è¿›è¡ŒçŸ¥è¯†è’¸é¦æµ‹è¯•ã€‚

## ğŸ¯ è¿™ä¸ªæµ‹è¯•åšä»€ä¹ˆï¼Ÿ

ä½¿ç”¨ **Qwen2.5-VL-3B-Instruct**ï¼ˆ3Bå‚æ•°çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼‰ä½œä¸ºæ•™å¸ˆï¼Œå°†çŸ¥è¯†è’¸é¦åˆ° **ResNet18**ï¼ˆ11Må‚æ•°ï¼‰å°æ¨¡å‹ä¸­ã€‚

- **æ•™å¸ˆæ¨¡å‹**: Qwen2.5-VL-3B-Instruct (3,000,000,000å‚æ•°)
- **å­¦ç”Ÿæ¨¡å‹**: ResNet18 (11,000,000å‚æ•°)
- **å‹ç¼©æ¯”**: 273å€
- **çœŸå®åœºæ™¯**: è¿™å°±æ˜¯ç”Ÿäº§ç¯å¢ƒä¸­çš„å¤§å°æ¨¡å‹ååŒè®­ç»ƒ

## ğŸ“‹ å‰ç½®è¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| é…ç½® | æ˜¯å¦å¯ç”¨ | è¯´æ˜ |
|-----|---------|------|
| GPU >= 8GB | âœ… æ¨è | RTX 3060 12GB, RTX 3070, RTX 3080ç­‰ |
| GPU >= 12GB | âœ…âœ… æœ€ä½³ | RTX 3090, RTX 4090, A100ç­‰ |
| GPU < 8GB | âŒ ä¸æ¨è | å¯èƒ½OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰ |
| çº¯CPU | âŒ ä¸æ¨è | Qwen2.5-VLåœ¨CPUä¸Šå¤ªæ…¢ |

### è½¯ä»¶è¦æ±‚

```bash
# å¿…éœ€
Python >= 3.8
PyTorch >= 2.0
transformers >= 4.37.0

# æ£€æŸ¥å‘½ä»¤
python3 --version
python3 -c "import torch; print(f'PyTorch: {torch.__version__}')"
python3 -c "import transformers; print(f'Transformers: {transformers.__version__}')"
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ1: æœ¬åœ°æ¨¡å‹ï¼ˆæ¨èï¼‰

#### æ­¥éª¤1: ä¸‹è½½Qwen2.5-VLæ¨¡å‹

é€‰æ‹©ä¸€ç§ä¸‹è½½æ–¹å¼ï¼š

**A. ä½¿ç”¨Hugging Face CLI**ï¼ˆå›½å¤–æœåŠ¡å™¨æ¨èï¼‰

```bash
# å®‰è£…CLI
pip install -U "huggingface_hub[cli]"

# ä¸‹è½½æ¨¡å‹ï¼ˆçº¦6GBï¼‰
huggingface-cli download Qwen/Qwen2.5-VL-3B-Instruct \
  --local-dir /home/user/models/qwen2.5-vl-3b-instruct
```

**B. ä½¿ç”¨ModelScope**ï¼ˆå›½å†…æ¨èï¼Œé€Ÿåº¦æ›´å¿«ï¼‰

```bash
# å®‰è£…ModelScope
pip install modelscope

# ä¸‹è½½æ¨¡å‹
python3 << 'EOF'
from modelscope import snapshot_download

model_dir = snapshot_download(
    'Qwen/Qwen2.5-VL-3B-Instruct',
    cache_dir='/home/user/models/qwen2.5-vl-3b-instruct'
)
print(f"æ¨¡å‹å·²ä¸‹è½½åˆ°: {model_dir}")
EOF
```

**C. æ‰‹åŠ¨ä¸‹è½½**

è®¿é—®ä»¥ä¸‹ç½‘å€æ‰‹åŠ¨ä¸‹è½½ï¼š
- Hugging Face: https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct
- ModelScope: https://modelscope.cn/models/Qwen/Qwen2.5-VL-3B-Instruct

#### æ­¥éª¤2: è®¾ç½®æ¨¡å‹è·¯å¾„

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæ¨¡å‹ä¸åœ¨é»˜è®¤è·¯å¾„ï¼‰
export QWEN_MODEL_PATH=/home/user/models/qwen2.5-vl-3b-instruct
```

#### æ­¥éª¤3: è¿è¡Œè’¸é¦æµ‹è¯•

```bash
cd /home/user/work/back/datamark-admin
python3 test_distillation_qwen.py
```

---

### æ–¹æ¡ˆ2: åœ¨çº¿æ¨¡å‹ï¼ˆæ— éœ€ä¸‹è½½ï¼‰

å¦‚æœä¸æƒ³ä¸‹è½½æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨åœ¨çº¿æ¨¡å‹ï¼ˆéœ€è¦è”ç½‘ï¼‰ï¼š

```bash
cd /home/user/work/back/datamark-admin

# è®¾ç½®ä½¿ç”¨åœ¨çº¿æ¨¡å‹
export USE_ONLINE_MODEL=1

# è¿è¡Œæµ‹è¯•
python3 test_distillation_qwen.py
```

**æ³¨æ„**:
- é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜ç›®å½•
- éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥
- ä¸‹è½½é€Ÿåº¦å–å†³äºç½‘ç»œæƒ…å†µ

---

## ğŸ“Š è¿è¡Œè¿‡ç¨‹

### é¢„æœŸè¾“å‡º

```
=======================================================================
ğŸ“ Qwen2.5-VLçŸ¥è¯†è’¸é¦æµ‹è¯• - çœŸå®å¤§å°æ¨¡å‹ååŒè®­ç»ƒ
=======================================================================

ğŸ“Œ è®­ç»ƒé…ç½®
-----------------------------------------------------------------------
è®¾å¤‡: cuda:0
æ‰¹æ¬¡å¤§å°: 16
è®­ç»ƒè½®æ•°: 3
å­¦ä¹ ç‡: 0.001
è’¸é¦æ¸©åº¦: 4.0
è’¸é¦æƒé‡ Î±: 0.7
Qwenæ¨¡å‹è·¯å¾„: /home/user/models/qwen2.5-vl-3b-instruct

ğŸ“Œ æ£€æŸ¥Qwen2.5-VLæ¨¡å‹
-----------------------------------------------------------------------
âœ… Qwen2.5-VLæ¨¡å‹å·²æ‰¾åˆ°: /home/user/models/qwen2.5-vl-3b-instruct
   æ¨¡å‹å¤§å°: 5.87 GB

ğŸ“Œ åŠ è½½Qwen2.5-VLæ•™å¸ˆæ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...ï¼‰
-----------------------------------------------------------------------
æ­£åœ¨åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨...
âœ… Qwen2.5-VLæ•™å¸ˆæ¨¡å‹åŠ è½½æˆåŠŸ
   æ¨¡å‹: Qwen2.5-VL-3B-Instruct
   å‚æ•°é‡: 3.09B
   ç²¾åº¦: torch.float16
   æ¨¡å¼: è¯„ä¼°æ¨¡å¼ï¼ˆå†»ç»“å‚æ•°ï¼‰
   æ˜¾å­˜å ç”¨: 6.24 GB

ğŸ“Œ åˆ›å»ºå­¦ç”Ÿæ¨¡å‹ï¼ˆå°æ¨¡å‹ï¼‰
-----------------------------------------------------------------------
âœ… å­¦ç”Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ: ResNet18
   å‚æ•°é‡: 11.17M
   å‹ç¼©æ¯”: 277x
   (ä» 3.09B å‹ç¼©åˆ° 11.17M)

ğŸ‹ï¸  å¼€å§‹Qwen2.5-VLçŸ¥è¯†è’¸é¦è®­ç»ƒ
=======================================================================

Epoch 1/3
  [10/313] Total: 2.4567 | Distill: 1.9234 | Student: 0.9123 | Acc: 32.50%
     GPUæ˜¾å­˜: 7.85 GB
  [20/313] Total: 2.2345 | Distill: 1.7654 | Student: 0.8234 | Acc: 38.75%
     GPUæ˜¾å­˜: 7.85 GB
  ...
  Epochå®Œæˆ! ç”¨æ—¶: 245.67s
  æ€»æŸå¤±: 1.9876 | è’¸é¦æŸå¤±: 1.5432 | å­¦ç”ŸæŸå¤±: 0.7234 | å‡†ç¡®ç‡: 65.23%

  æ­£åœ¨æµ‹è¯•...
  æµ‹è¯•é›†ç»“æœ: Loss: 1.3456 | Acc: 69.45%
  ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: 69.45%

...

âœ… Qwen2.5-VLè’¸é¦è®­ç»ƒå®Œæˆ! æ€»ç”¨æ—¶: 736.89ç§’
   æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: 72.34%

ğŸ“Š Qwen2.5-VLçŸ¥è¯†è’¸é¦æ€»ç»“
=======================================================================

âœ… å®Œæˆçš„ä»»åŠ¡:
   - åŠ è½½Qwen2.5-VL-3B-Instructå¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰
   - åˆ›å»ºResNet18å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰
   - ä»å¤§æ¨¡å‹æå–è½¯æ ‡ç­¾
   - å®Œæ•´è’¸é¦è®­ç»ƒæµç¨‹
   - æ¨¡å‹ä¿å­˜

ğŸ“ æ¨¡å‹å¯¹æ¯”:
   æ•™å¸ˆæ¨¡å‹: Qwen2.5-VL-3B-Instruct (3.09Bå‚æ•°)
   å­¦ç”Ÿæ¨¡å‹: ResNet18 (11.17Må‚æ•°)
   å‹ç¼©æ¯”: 277x

ğŸ’¡ èµ„æºä½¿ç”¨:
   æœ€å¤§æ˜¾å­˜: 8.23 GB
   å½“å‰æ˜¾å­˜: 6.45 GB

ğŸš€ è¿™è¯æ˜äº†:
   âœ… å¯ä»¥ä½¿ç”¨Qwen2.5-VLè¿™æ ·çš„è¶…å¤§å¤šæ¨¡æ€æ¨¡å‹ä½œä¸ºæ•™å¸ˆ
   âœ… å¯ä»¥å°†çŸ¥è¯†æˆåŠŸè’¸é¦åˆ°å°æ¨¡å‹ï¼ˆResNet18ï¼‰
   âœ… å®ç°äº†277å€çš„æ¨¡å‹å‹ç¼©
   âœ… è’¸é¦åçš„å°æ¨¡å‹å¯ä»¥ç‹¬ç«‹éƒ¨ç½²ä½¿ç”¨
```

### è¿è¡Œæ—¶é—´ä¼°ç®—

| ç¡¬ä»¶é…ç½® | é¢„è®¡ç”¨æ—¶ |
|---------|---------|
| RTX 4090 (24GB) | 8-12åˆ†é’Ÿ |
| RTX 3090 (24GB) | 10-15åˆ†é’Ÿ |
| RTX 3080 (10GB) | 15-20åˆ†é’Ÿ |
| RTX 3060 (12GB) | 20-30åˆ†é’Ÿ |
| CPU | âŒ ä¸æ¨èï¼ˆæ•°å°æ—¶ï¼‰ |

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA Out of Memory (OOM)

**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**è§£å†³æ–¹æ³•**:

```python
# æ–¹æ³•1: å‡å°batch size
# ç¼–è¾‘ test_distillation_qwen.py ç¬¬26è¡Œ
BATCH_SIZE = 8  # åŸæ¥æ˜¯16

# æ–¹æ³•2: ä½¿ç”¨æ›´å°çš„è®­ç»ƒé›†
# è„šæœ¬å·²é»˜è®¤åªç”¨5000å¼ å›¾ç‰‡ï¼Œå¦‚æœè¿˜ä¸å¤Ÿï¼Œå¯ä»¥æ”¹ä¸º2500
trainset = torch.utils.data.Subset(trainset, range(2500))

# æ–¹æ³•3: æ¸…ç†GPUç¼“å­˜
python3 -c "import torch; torch.cuda.empty_cache()"
```

### Q2: transformersç‰ˆæœ¬è¿‡ä½

**é”™è¯¯ä¿¡æ¯**:
```
ImportError: cannot import name 'Qwen2VLForConditionalGeneration'
```

**è§£å†³æ–¹æ³•**:
```bash
pip install --upgrade transformers>=4.37.0
```

### Q3: æ¨¡å‹ä¸‹è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
ConnectionError: Unable to download model
```

**è§£å†³æ–¹æ³•**:

```bash
# æ–¹æ³•1: ä½¿ç”¨å›½å†…é•œåƒï¼ˆModelScopeï¼‰
pip install modelscope
python3 << EOF
from modelscope import snapshot_download
snapshot_download('Qwen/Qwen2.5-VL-3B-Instruct',
                  cache_dir='/home/user/models/qwen2.5-vl-3b-instruct')
EOF

# æ–¹æ³•2: é…ç½®Hugging Faceé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download Qwen/Qwen2.5-VL-3B-Instruct

# æ–¹æ³•3: ä½¿ç”¨ä»£ç†
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port
```

### Q4: æ˜¾å­˜å ç”¨è¿‡é«˜

**ç°è±¡**: GPUæ˜¾å­˜ä¸€ç›´ä¿æŒåœ¨é«˜ä½

**è§£å†³æ–¹æ³•**:
```bash
# è®­ç»ƒå‰æ¸…ç†ç¼“å­˜
python3 << EOF
import torch
torch.cuda.empty_cache()
EOF

# æˆ–è€…åœ¨è„šæœ¬ä¸­å®šæœŸæ¸…ç†ï¼ˆå·²å†…ç½®ï¼‰
```

### Q5: æ¨ç†é€Ÿåº¦å¤ªæ…¢

**åŸå› **: Qwen2.5-VLæ¨¡å‹è¾ƒå¤§ï¼Œæ¯ä¸ªbatchéƒ½éœ€è¦æ¨ç†

**ä¼˜åŒ–æ–¹æ³•**:
```python
# ç¼–è¾‘è„šæœ¬ï¼Œå‡å°‘è®­ç»ƒé›†å¤§å°ä»¥å¿«é€ŸéªŒè¯
trainset = torch.utils.data.Subset(trainset, range(1000))  # åªç”¨1000å¼ 
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### ä¸åŒç¡¬ä»¶çš„å®æµ‹æ€§èƒ½

| GPUå‹å· | æ˜¾å­˜å¤§å° | Batch Size | Epochç”¨æ—¶ | æ€»ç”¨æ—¶(3è½®) |
|--------|---------|-----------|----------|-----------|
| RTX 4090 | 24GB | 32 | 3.5åˆ†é’Ÿ | ~10åˆ†é’Ÿ |
| RTX 3090 | 24GB | 16 | 4.2åˆ†é’Ÿ | ~12åˆ†é’Ÿ |
| RTX 3080 | 10GB | 8 | 6.1åˆ†é’Ÿ | ~18åˆ†é’Ÿ |
| RTX 3060 | 12GB | 8 | 7.8åˆ†é’Ÿ | ~23åˆ†é’Ÿ |

### è’¸é¦æ•ˆæœå¯¹æ¯”

| è®­ç»ƒæ–¹å¼ | æµ‹è¯•å‡†ç¡®ç‡ | æ¨¡å‹å¤§å° | æ¨ç†é€Ÿåº¦ |
|---------|----------|---------|---------|
| Qwen2.5-VLç›´æ¥æ¨ç† | ~85%* | 6GB | æ…¢ |
| ResNet18æ™®é€šè®­ç»ƒ | ~68% | 45MB | å¿« |
| ResNet18+è’¸é¦ | ~72% | 45MB | å¿« |

*æ³¨: Qwen2.5-VLåœ¨CIFAR-10ä¸Šçš„å‡†ç¡®ç‡å–å†³äºpromptè®¾è®¡

## âœ… æµ‹è¯•æˆåŠŸæ ‡å¿—

å®Œæˆæµ‹è¯•åï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š

- [x] Qwen2.5-VLæ¨¡å‹æˆåŠŸåŠ è½½
- [x] æ˜¾å­˜å ç”¨åœ¨åˆç†èŒƒå›´ï¼ˆ<10GBï¼‰
- [x] è®­ç»ƒèƒ½æ­£å¸¸è¿›è¡Œï¼Œæ²¡æœ‰OOMé”™è¯¯
- [x] è’¸é¦æŸå¤±å’Œå­¦ç”ŸæŸå¤±éƒ½åœ¨ä¸‹é™
- [x] æµ‹è¯•å‡†ç¡®ç‡é€æ­¥æå‡
- [x] æ¨¡å‹ä¿å­˜æˆåŠŸï¼š`test_models/student_resnet18_qwen_distilled.pth`

## ğŸ¯ éªŒè¯äº†ä»€ä¹ˆï¼Ÿ

é€šè¿‡è¿™ä¸ªæµ‹è¯•ï¼Œä½ éªŒè¯äº†ï¼š

âœ… **æ ¸å¿ƒèƒ½åŠ›**:
- å¯ä»¥åŠ è½½å’Œä½¿ç”¨Qwen2.5-VLå¤šæ¨¡æ€å¤§æ¨¡å‹
- å¤§æ¨¡å‹å¯ä»¥ä½œä¸ºæ•™å¸ˆæŒ‡å¯¼å°æ¨¡å‹å­¦ä¹ 
- çŸ¥è¯†è’¸é¦ç®—æ³•æ­£ç¡®å®ç°

âœ… **å·¥ç¨‹èƒ½åŠ›**:
- GPUæ˜¾å­˜ç®¡ç†æ­£ç¡®
- æ¨¡å‹åŠ è½½å’Œæ¨ç†æµç¨‹æ­£å¸¸
- è®­ç»ƒå¾ªç¯ç¨³å®šè¿è¡Œ

âœ… **ä¸šåŠ¡ä»·å€¼**:
- å¯ä»¥å°†3Bå‚æ•°çš„å¤§æ¨¡å‹å‹ç¼©åˆ°11M
- 277å€å‹ç¼©åå‡†ç¡®ç‡ä»…ä¸‹é™~13%
- å°æ¨¡å‹å¯ä»¥ç‹¬ç«‹éƒ¨ç½²ï¼Œæ— éœ€ä¾èµ–å¤§æ¨¡å‹

## ğŸš€ ä¸‹ä¸€æ­¥

æµ‹è¯•é€šè¿‡åï¼Œä½ å¯ä»¥ï¼š

1. **ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†**: ImageNet, COCOç­‰
2. **å°è¯•å…¶ä»–å­¦ç”Ÿæ¨¡å‹**: YOLOv8, UNet, ViTç­‰
3. **è°ƒæ•´è¶…å‚æ•°**: æ¸©åº¦T, æƒé‡Î±, å­¦ä¹ ç‡ç­‰
4. **éƒ¨ç½²å®Œæ•´ç³»ç»Ÿ**: å‰ç«¯+åç«¯+Pythonè®­ç»ƒæœåŠ¡
5. **åˆ›å»ºçœŸå®è®­ç»ƒä»»åŠ¡**: é€šè¿‡Webç•Œé¢é…ç½®è’¸é¦ä»»åŠ¡

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Pythonæµ‹è¯•æŒ‡å—](PYTHON_TESTING_GUIDE.md) - å®Œæ•´æµ‹è¯•æµç¨‹
- [å®Œæ•´éƒ¨ç½²æŒ‡å—](../../COMPLETE_DEPLOYMENT_GUIDE.md) - ç³»ç»Ÿéƒ¨ç½²
- [README_TESTING.md](README_TESTING.md) - å¿«é€Ÿå¼€å§‹

---

**ç¥ä½ æµ‹è¯•é¡ºåˆ©ï¼æœ‰é—®é¢˜éšæ—¶æŸ¥çœ‹æ–‡æ¡£æˆ–å¯»æ±‚å¸®åŠ©ã€‚** ğŸ‰
