# Qwen2.5-VL è’¸é¦è®­ç»ƒé…ç½®ç¤ºä¾‹

æœ¬ç›®å½•åŒ…å«äº†å„ç§å­¦ç”Ÿæ¨¡å‹çš„é…ç½®ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨Qwen2.5-VLä½œä¸ºæ•™å¸ˆæ¨¡å‹è¿›è¡ŒçŸ¥è¯†è’¸é¦è®­ç»ƒã€‚

## ğŸ“ é…ç½®æ–‡ä»¶åˆ—è¡¨

### 1. ResNet50 åˆ†ç±»ä»»åŠ¡
**æ–‡ä»¶**: `qwen_vl_resnet50_example.json`

**é€‚ç”¨åœºæ™¯**: å›¾åƒåˆ†ç±»ï¼Œå¹³è¡¡å‡†ç¡®ç‡å’Œé€Ÿåº¦

**å…³é”®é…ç½®**:
- å­¦ç”Ÿæ¨¡å‹: ResNet50
- è’¸é¦ç­–ç•¥: Hybrid (ç‰¹å¾+Logits+ä»»åŠ¡æŸå¤±)
- æ‰¹å¤§å°: 32
- å­¦ä¹ ç‡: 1e-4
- æ¨èæ•°æ®é›†: CIFAR-10, CIFAR-100, ImageNetå­é›†

**å‘½ä»¤è¡Œè¿è¡Œ**:
```bash
python train_qwen_vl_distillation.py \
    --task_id "resnet50_task" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "resnet" \
    --student_model_size "resnet50" \
    --task_type "classification" \
    --num_classes 10 \
    --dataset_path "/data/datasets/cifar10/train" \
    --val_dataset_path "/data/datasets/cifar10/val" \
    --image_size 224 \
    --epochs 100 \
    --batch_size 32 \
    --learning_rate 1e-4 \
    --optimizer_type "adamw" \
    --lr_scheduler "cosine" \
    --distillation_type "hybrid" \
    --alpha 0.5 --beta 0.3 --gamma 0.2 \
    --feature_loss_type "cosine" \
    --align_feature \
    --use_amp \
    --gpu_devices "0" \
    --output_dir "/data/outputs/qwen_resnet50"
```

---

### 2. Vision Transformer åˆ†ç±»ä»»åŠ¡
**æ–‡ä»¶**: `qwen_vl_vit_example.json`

**é€‚ç”¨åœºæ™¯**: éœ€è¦é«˜å‡†ç¡®ç‡çš„å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œæ¶æ„ç›¸ä¼¼çš„Transformerè’¸é¦

**å…³é”®é…ç½®**:
- å­¦ç”Ÿæ¨¡å‹: ViT-Base
- è’¸é¦ç­–ç•¥: Layer-wise (é€å±‚å¯¹é½)
- æ‰¹å¤§å°: 64
- å­¦ä¹ ç‡: 5e-5 (Transformerå¯¹å­¦ä¹ ç‡æ•æ„Ÿ)
- æ¨èæ•°æ®é›†: ImageNetå­é›†, ç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†

**å‘½ä»¤è¡Œè¿è¡Œ**:
```bash
python train_qwen_vl_distillation.py \
    --task_id "vit_base_task" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "vit" \
    --student_model_size "vit-base" \
    --task_type "classification" \
    --num_classes 100 \
    --dataset_path "/data/datasets/imagenet_subset/train" \
    --val_dataset_path "/data/datasets/imagenet_subset/val" \
    --image_size 224 \
    --epochs 50 \
    --batch_size 64 \
    --learning_rate 5e-5 \
    --optimizer_type "adamw" \
    --lr_scheduler "cosine" \
    --weight_decay 0.05 \
    --grad_accum_steps 2 \
    --distillation_type "layer" \
    --alpha 0.4 --beta 0.4 --gamma 0.2 \
    --feature_loss_type "mse" \
    --align_feature \
    --feature_dim 768 \
    --use_amp \
    --gpu_devices "0,1" \
    --output_dir "/data/outputs/qwen_vit_base"
```

---

### 3. YOLOv8 ç›®æ ‡æ£€æµ‹ä»»åŠ¡
**æ–‡ä»¶**: `qwen_vl_yolov8_example.json`

**é€‚ç”¨åœºæ™¯**: å®æ—¶ç›®æ ‡æ£€æµ‹ï¼Œè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²

**å…³é”®é…ç½®**:
- å­¦ç”Ÿæ¨¡å‹: YOLOv8-s
- è’¸é¦ç­–ç•¥: Feature-only (ç‰¹å¾è’¸é¦)
- æ‰¹å¤§å°: 16
- å­¦ä¹ ç‡: 1e-3 (æ£€æµ‹ä»»åŠ¡éœ€è¦è¾ƒå¤§å­¦ä¹ ç‡)
- å›¾åƒå¤§å°: 640x640
- æ¨èæ•°æ®é›†: COCO, VOC, è‡ªå®šä¹‰æ£€æµ‹æ•°æ®é›†

**å‘½ä»¤è¡Œè¿è¡Œ**:
```bash
python train_qwen_vl_distillation.py \
    --task_id "yolov8_task" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "yolov8" \
    --student_model_size "s" \
    --task_type "detection" \
    --num_classes 80 \
    --dataset_path "/data/datasets/coco/train" \
    --val_dataset_path "/data/datasets/coco/val" \
    --image_size 640 \
    --epochs 300 \
    --batch_size 16 \
    --learning_rate 1e-3 \
    --optimizer_type "sgd" \
    --lr_scheduler "cosine" \
    --weight_decay 0.0005 \
    --max_grad_norm 10.0 \
    --distillation_type "feature" \
    --gamma 1.0 \
    --feature_loss_type "mse" \
    --align_feature \
    --feature_dim 512 \
    --gpu_devices "0" \
    --output_dir "/data/outputs/qwen_yolov8s"
```

---

## ğŸ¯ å¦‚ä½•é€‰æ‹©é…ç½®

### æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©

| ä»»åŠ¡ç±»å‹ | æ¨èé…ç½® | ç†ç”± |
|---------|---------|------|
| **å›¾åƒåˆ†ç±» (å°è§„æ¨¡, <50ç±»)** | ResNet50 | å¿«é€Ÿæ”¶æ•›ï¼Œæ€§èƒ½å¥½ |
| **å›¾åƒåˆ†ç±» (å¤§è§„æ¨¡, >100ç±»)** | ViT-Base | æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ› |
| **å®æ—¶ç›®æ ‡æ£€æµ‹** | YOLOv8-s/n | é€Ÿåº¦å¿«ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡ |
| **é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹** | YOLOv8-m/l | å‡†ç¡®ç‡æ›´é«˜ |
| **å›¾åƒåˆ†å‰²** | UNet | ä¸“é—¨ä¸ºåˆ†å‰²è®¾è®¡ |
| **è§†é¢‘åˆ†ç±»/è¡Œä¸ºè¯†åˆ«** | LSTM | å¤„ç†æ—¶åºä¿¡æ¯ |

### æ ¹æ®è®¡ç®—èµ„æºé€‰æ‹©

| GPUæ˜¾å­˜ | æ¨èé…ç½® | è°ƒæ•´å»ºè®® |
|---------|---------|---------|
| **12GB-16GB** | ResNet50, batch=16 | å‡å°batch_sizeï¼Œä½¿ç”¨æ··åˆç²¾åº¦ |
| **24GB** | ViT-Base, batch=32 | æ ‡å‡†é…ç½® |
| **32GB+** | ViT-Large, batch=64 | å¯ä»¥è®­ç»ƒæ›´å¤§æ¨¡å‹ |

### æ ¹æ®æ•°æ®é›†å¤§å°é€‰æ‹©

| æ•°æ®é›†å¤§å° | è®­ç»ƒç­–ç•¥ | epochs |
|-----------|---------|--------|
| **< 1000æ ·æœ¬** | ä½¿ç”¨é¢„è®­ç»ƒ + è½»é‡è’¸é¦ | 50-100 |
| **1000-10000æ ·æœ¬** | æ ‡å‡†è’¸é¦é…ç½® | 100-200 |
| **> 10000æ ·æœ¬** | å®Œæ•´è’¸é¦è®­ç»ƒ | 200-500 |

---

## ğŸ”§ é…ç½®æ–‡ä»¶ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1: ç›´æ¥ä½¿ç”¨JSONé…ç½®ï¼ˆéœ€è¦å®ç°é…ç½®è§£æå™¨ï¼‰

```python
# config_parser.py
import json
import argparse

def load_config_from_json(json_path):
    with open(json_path, 'r') as f:
        config = json.load(f)

    # è½¬æ¢ä¸ºå‘½ä»¤è¡Œå‚æ•°æ ¼å¼
    args = argparse.Namespace(
        task_id=config.get('task_name', 'default_task'),
        api_base_url=config.get('api_base_url', 'http://localhost:8080/api'),
        teacher_model_path=config['teacher_model']['model_path'],
        student_model_type=config['student_model']['type'],
        student_model_size=config['student_model']['size'],
        # ... å…¶ä»–å‚æ•°æ˜ å°„
    )
    return args

# ä½¿ç”¨
args = load_config_from_json('config_examples/qwen_vl_resnet50_example.json')
```

### æ–¹å¼2: å‚è€ƒJSONï¼Œä½¿ç”¨å‘½ä»¤è¡Œï¼ˆæ¨èï¼‰

ç›´æ¥å¤åˆ¶ä¸Šé¢æä¾›çš„å‘½ä»¤è¡Œç¤ºä¾‹ï¼Œæ ¹æ®å®é™…è·¯å¾„è°ƒæ•´å‚æ•°ã€‚

### æ–¹å¼3: åœ¨å‰ç«¯é…ç½®é¡µé¢å¯¼å…¥JSON

å‰ç«¯Vueé¡µé¢æ”¯æŒJSONå¯¼å…¥åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥åŠ è½½è¿™äº›é…ç½®æ–‡ä»¶ï¼š

```javascript
// å‰ç«¯ä»£ç ç¤ºä¾‹
const loadConfig = async (jsonFile) => {
  const response = await fetch(jsonFile);
  const config = await response.json();

  // å¡«å……è¡¨å•
  taskModel.value = {
    teacherModel: config.teacher_model.model_path,
    studentModel: `${config.student_model.type}-${config.student_model.size}`,
    epochs: config.training.epochs,
    batchSize: config.training.batch_size,
    // ... å…¶ä»–å­—æ®µ
  };
};
```

---

## ğŸ“ é…ç½®å‚æ•°è¯´æ˜

### æ•™å¸ˆæ¨¡å‹ (teacher_model)

```json
{
  "type": "qwen2.5-vl",           // å›ºå®šå€¼
  "model_path": "/path/to/model", // Qwen2.5-VLæ¨¡å‹è·¯å¾„
  "freeze_weights": true          // æ˜¯å¦å†»ç»“æƒé‡ï¼ˆæ¨ètrueï¼‰
}
```

### å­¦ç”Ÿæ¨¡å‹ (student_model)

```json
{
  "type": "resnet|vit|yolov8|unet|lstm",  // æ¨¡å‹ç±»å‹
  "size": "resnet50|vit-base|s|medium",   // æ¨¡å‹å¤§å°
  "pretrained": true,                     // æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
  "num_classes": 10                       // åˆ†ç±»ç±»åˆ«æ•°
}
```

### è®­ç»ƒé…ç½® (training)

```json
{
  "task_type": "classification|detection|segmentation",
  "epochs": 100,                   // è®­ç»ƒè½®æ•°
  "batch_size": 32,                // æ‰¹å¤§å°
  "image_size": 224,               // å›¾åƒå°ºå¯¸
  "learning_rate": 0.0001,         // å­¦ä¹ ç‡
  "optimizer": "adamw|adam|sgd",   // ä¼˜åŒ–å™¨
  "lr_scheduler": "cosine|linear|step",  // å­¦ä¹ ç‡è°ƒåº¦å™¨
  "weight_decay": 0.01,            // æƒé‡è¡°å‡
  "grad_accum_steps": 1,           // æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
  "max_grad_norm": 1.0,            // æ¢¯åº¦è£å‰ª
  "use_amp": true                  // æ··åˆç²¾åº¦è®­ç»ƒ
}
```

### è’¸é¦é…ç½® (distillation)

```json
{
  "type": "feature|logit|layer|hybrid",  // è’¸é¦ç±»å‹
  "temperature": 4.0,                    // è’¸é¦æ¸©åº¦
  "alpha": 0.5,                          // ç¡¬æ ‡ç­¾æƒé‡
  "beta": 0.3,                           // è½¯æ ‡ç­¾æƒé‡
  "gamma": 0.2,                          // ç‰¹å¾è’¸é¦æƒé‡
  "feature_loss_type": "mse|cosine",     // ç‰¹å¾æŸå¤±ç±»å‹
  "align_feature": true,                 // ä½¿ç”¨ç‰¹å¾å¯¹é½å±‚
  "feature_dim": 768                     // ç‰¹å¾å¯¹é½ç»´åº¦
}
```

**æ³¨æ„**: alpha + beta + gamma ä¸ä¸€å®šç­‰äº1ï¼Œå¯ä»¥æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ã€‚

---

## ğŸš€ å¿«é€Ÿæµ‹è¯•

### æœ€å°åŒ–é…ç½®ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰

```bash
python train_qwen_vl_distillation.py \
    --task_id "quick_test" \
    --api_base_url "http://localhost:8080/api" \
    --teacher_model_path "/data/models/qwen2.5-vl-8b" \
    --student_model_type "resnet" \
    --student_model_size "resnet18" \
    --task_type "classification" \
    --num_classes 10 \
    --dataset_path "/data/datasets/test/train" \
    --val_dataset_path "/data/datasets/test/val" \
    --image_size 224 \
    --epochs 5 \
    --batch_size 16 \
    --learning_rate 1e-4 \
    --distillation_type "feature" \
    --gamma 1.0 \
    --gpu_devices "0" \
    --output_dir "/tmp/quick_test"
```

**ç”¨é€”**: å¿«é€ŸéªŒè¯ç¯å¢ƒé…ç½®æ˜¯å¦æ­£ç¡®ï¼Œè®­ç»ƒæµç¨‹æ˜¯å¦å¯ä»¥è¿è¡Œã€‚

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### æå‡è®­ç»ƒé€Ÿåº¦

1. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**
   ```json
   "use_amp": true
   ```

2. **æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§æ‰¹é‡**
   ```json
   "batch_size": 16,
   "grad_accum_steps": 4  // ç­‰æ•ˆbatch_size=64
   ```

3. **å‡å°å›¾åƒå°ºå¯¸**
   ```json
   "image_size": 192  // ä»224å‡å°åˆ°192
   ```

### æå‡æ¨¡å‹æ€§èƒ½

1. **å¢åŠ è’¸é¦æƒé‡**
   ```json
   "alpha": 0.3,  // å‡å°ä»»åŠ¡æŸå¤±
   "beta": 0.4,   // å¢å¤§è½¯æ ‡ç­¾
   "gamma": 0.3   // å¢å¤§ç‰¹å¾è’¸é¦
   ```

2. **ä½¿ç”¨æ··åˆè’¸é¦ç­–ç•¥**
   ```json
   "type": "hybrid"
   ```

3. **å¯ç”¨ç‰¹å¾å¯¹é½**
   ```json
   "align_feature": true,
   "feature_dim": 768
   ```

### å¤„ç†è¿‡æ‹Ÿåˆ

1. **å¢åŠ æ•°æ®å¢å¼º**ï¼ˆä¿®æ”¹ä»£ç ï¼‰
   ```python
   transforms.RandomAffine(degrees=20, translate=(0.1, 0.1))
   transforms.RandomErasing(p=0.2)
   ```

2. **å¢åŠ æƒé‡è¡°å‡**
   ```json
   "weight_decay": 0.05  // ä»0.01å¢åŠ åˆ°0.05
   ```

3. **é™ä½å­¦ä¹ ç‡**
   ```json
   "learning_rate": 0.00005  // ä»1e-4é™åˆ°5e-5
   ```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ä¸»æ–‡æ¡£: QWEN_VL_DISTILLATION_GUIDE.md](../QWEN_VL_DISTILLATION_GUIDE.md)
- [è®­ç»ƒè„šæœ¬: train_qwen_vl_distillation.py](../train_qwen_vl_distillation.py)

---

**æœ€åæ›´æ–°**: 2026-01-11
**ç»´æŠ¤è€…**: Claude Assistant
