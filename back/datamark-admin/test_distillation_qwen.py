#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen2.5-VLçŸ¥è¯†è’¸é¦æµ‹è¯•è„šæœ¬
ä½¿ç”¨Qwen2.5-VL-3B-Instructä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œè’¸é¦åˆ°å°æ¨¡å‹

è¿™æ˜¯çœŸå®çš„å¤§å°æ¨¡å‹ååŒè®­ç»ƒåœºæ™¯ï¼š
- æ•™å¸ˆæ¨¡å‹ï¼šQwen2.5-VL-3B-Instruct (3Bå‚æ•°ï¼Œå¤šæ¨¡æ€å¤§æ¨¡å‹)
- å­¦ç”Ÿæ¨¡å‹ï¼šResNet18 (11Må‚æ•°)
- å‹ç¼©æ¯”ï¼š273x

ä½œè€…ï¼šClaude Assistant
æ—¥æœŸï¼š2026-01-14
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from pathlib import Path
import time
import sys
import os

print("=" * 80)
print("ğŸ“ Qwen2.5-VLçŸ¥è¯†è’¸é¦æµ‹è¯• - çœŸå®å¤§å°æ¨¡å‹ååŒè®­ç»ƒ")
print("=" * 80)
print()

# ==================== é…ç½® ====================
BATCH_SIZE = 16  # Qwen2.5-VLæ˜¾å­˜å ç”¨å¤§ï¼Œå‡å°batch size
NUM_EPOCHS = 3
LEARNING_RATE = 0.001
NUM_WORKERS = 2
TEMPERATURE = 4.0
ALPHA = 0.7
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Qwen2.5-VLæ¨¡å‹è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
QWEN_MODEL_PATH = os.environ.get('QWEN_MODEL_PATH', '/home/user/models/qwen2.5-vl-3b-instruct')

print(f"ğŸ“Œ è®­ç»ƒé…ç½®")
print("-" * 80)
print(f"è®¾å¤‡: {DEVICE}")
print(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"è®­ç»ƒè½®æ•°: {NUM_EPOCHS}")
print(f"å­¦ä¹ ç‡: {LEARNING_RATE}")
print(f"è’¸é¦æ¸©åº¦: {TEMPERATURE}")
print(f"è’¸é¦æƒé‡ Î±: {ALPHA}")
print(f"Qwenæ¨¡å‹è·¯å¾„: {QWEN_MODEL_PATH}")
print()

# ==================== æ£€æŸ¥ä¾èµ– ====================
print("ğŸ“Œ æ£€æŸ¥ä¾èµ–åº“")
print("-" * 80)

try:
    from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
    print("âœ… transformersåº“å·²å®‰è£…")
except ImportError:
    print("âŒ transformersåº“æœªå®‰è£…")
    print("   å®‰è£…å‘½ä»¤: pip install transformers>=4.37.0")
    sys.exit(1)

try:
    from qwen_vl_utils import process_vision_info
    print("âœ… qwen-vl-utilså·²å®‰è£…")
except ImportError:
    print("âš ï¸  qwen-vl-utilsæœªå®‰è£…ï¼ˆå¯é€‰ï¼‰")
    print("   å®‰è£…å‘½ä»¤: pip install qwen-vl-utils")

print()

# ==================== æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ ====================
print("ğŸ“Œ æ£€æŸ¥Qwen2.5-VLæ¨¡å‹")
print("-" * 80)

qwen_path = Path(QWEN_MODEL_PATH)
if not qwen_path.exists():
    print(f"âŒ Qwen2.5-VLæ¨¡å‹æœªæ‰¾åˆ°: {QWEN_MODEL_PATH}")
    print()
    print("è¯·å…ˆä¸‹è½½æ¨¡å‹ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼š")
    print()
    print("æ–¹å¼1: ä½¿ç”¨Hugging Face CLI")
    print("---------------------------------------")
    print("huggingface-cli download Qwen/Qwen2.5-VL-3B-Instruct \\")
    print("  --local-dir /home/user/models/qwen2.5-vl-3b-instruct")
    print()
    print("æ–¹å¼2: ä½¿ç”¨ModelScopeï¼ˆå›½å†…æ¨èï¼‰")
    print("---------------------------------------")
    print("pip install modelscope")
    print("python << EOF")
    print("from modelscope import snapshot_download")
    print("snapshot_download('Qwen/Qwen2.5-VL-3B-Instruct',")
    print("                  cache_dir='/home/user/models/qwen2.5-vl-3b-instruct')")
    print("EOF")
    print()
    print("æ–¹å¼3: ä½¿ç”¨åœ¨çº¿æ¨¡å‹ï¼ˆéœ€è¦è”ç½‘ï¼Œé€Ÿåº¦æ…¢ï¼‰")
    print("---------------------------------------")
    print("è®¾ç½®ç¯å¢ƒå˜é‡: export USE_ONLINE_MODEL=1")
    print("ç„¶åé‡æ–°è¿è¡Œæ­¤è„šæœ¬")
    print()

    use_online = os.environ.get('USE_ONLINE_MODEL', '0')
    if use_online == '1':
        print("âš ï¸  å°†ä½¿ç”¨åœ¨çº¿æ¨¡å‹ï¼ˆéœ€è¦è”ç½‘ï¼Œé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼‰")
        QWEN_MODEL_PATH = "Qwen/Qwen2.5-VL-3B-Instruct"
    else:
        print("å¦‚æœæƒ³å°è¯•åœ¨çº¿æ¨¡å‹ï¼Œè¯·è¿è¡Œ:")
        print("export USE_ONLINE_MODEL=1 && python3 test_distillation_qwen.py")
        sys.exit(1)
else:
    print(f"âœ… Qwen2.5-VLæ¨¡å‹å·²æ‰¾åˆ°: {QWEN_MODEL_PATH}")
    print(f"   æ¨¡å‹å¤§å°: {sum(f.stat().st_size for f in qwen_path.rglob('*') if f.is_file()) / 1024**3:.2f} GB")

print()

# ==================== å‡†å¤‡æ•°æ®é›† ====================
print("ğŸ“Œ å‡†å¤‡æ•°æ®é›†")
print("-" * 80)

dataset_root = Path("./datasets")
dataset_root.mkdir(exist_ok=True)

# CIFAR-10çš„å›¾åƒæ˜¯32x32ï¼Œéœ€è¦æ”¾å¤§åˆ°é€‚åˆQwen2.5-VLçš„å°ºå¯¸
transform_train = transforms.Compose([
    transforms.Resize(224),  # Qwen2.5-VLæ¨è224æˆ–æ›´å¤§
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # å½’ä¸€åŒ–åˆ°[-1,1]
])

transform_test = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

try:
    print("æ­£åœ¨åŠ è½½CIFAR-10...")
    trainset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=True,
        download=True,
        transform=transform_train
    )

    # ä¸ºäº†åŠ å¿«æµ‹è¯•ï¼Œåªä½¿ç”¨éƒ¨åˆ†æ•°æ®
    # å¦‚æœæƒ³å®Œæ•´è®­ç»ƒï¼Œæ³¨é‡Šæ‰ä¸‹é¢ä¸¤è¡Œ
    print("âš ï¸  ä¸ºåŠ å¿«æµ‹è¯•ï¼Œä»…ä½¿ç”¨å‰5000å¼ è®­ç»ƒå›¾ç‰‡")
    trainset = torch.utils.data.Subset(trainset, range(5000))

    testset = torchvision.datasets.CIFAR10(
        root=str(dataset_root),
        train=False,
        download=True,
        transform=transform_test
    )

    print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé›†: {len(trainset)} å¼ ")
    print(f"   æµ‹è¯•é›†: {len(testset)} å¼ ")
    print(f"   ç±»åˆ«: {trainset.dataset.classes if hasattr(trainset, 'dataset') else 'CIFAR-10 classes'}")

except Exception as e:
    print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

print()

# ==================== åŠ è½½Qwen2.5-VLæ•™å¸ˆæ¨¡å‹ ====================
print("ğŸ“Œ åŠ è½½Qwen2.5-VLæ•™å¸ˆæ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...ï¼‰")
print("-" * 80)

try:
    print("æ­£åœ¨åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨...")

    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨float16å‡å°‘æ˜¾å­˜å ç”¨ï¼‰
    teacher_model = Qwen2VLForConditionalGeneration.from_pretrained(
        QWEN_MODEL_PATH,
        torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,
        device_map="auto" if DEVICE.type == 'cuda' else None,
        trust_remote_code=True,
    )

    # å¦‚æœä¸æ˜¯è‡ªåŠ¨åˆ†é…åˆ°GPUï¼Œæ‰‹åŠ¨ç§»åŠ¨
    if DEVICE.type == 'cuda' and not hasattr(teacher_model, 'hf_device_map'):
        teacher_model = teacher_model.to(DEVICE)

    teacher_model.eval()

    # å†»ç»“æ•™å¸ˆæ¨¡å‹å‚æ•°
    for param in teacher_model.parameters():
        param.requires_grad = False

    # åŠ è½½å¤„ç†å™¨
    processor = AutoProcessor.from_pretrained(
        QWEN_MODEL_PATH,
        trust_remote_code=True
    )

    # è®¡ç®—å‚æ•°é‡
    teacher_params = sum(p.numel() for p in teacher_model.parameters()) / 1e9

    print(f"âœ… Qwen2.5-VLæ•™å¸ˆæ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   æ¨¡å‹: Qwen2.5-VL-3B-Instruct")
    print(f"   å‚æ•°é‡: {teacher_params:.2f}B")
    print(f"   ç²¾åº¦: {teacher_model.dtype}")
    print(f"   æ¨¡å¼: è¯„ä¼°æ¨¡å¼ï¼ˆå†»ç»“å‚æ•°ï¼‰")

    if DEVICE.type == 'cuda':
        print(f"   æ˜¾å­˜å ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")

except Exception as e:
    print(f"âŒ Qwen2.5-VLæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print()
    print("å¯èƒ½çš„åŸå› ï¼š")
    print("1. æ˜¾å­˜ä¸è¶³ï¼ˆQwen2.5-VL-3Bè‡³å°‘éœ€è¦8GBæ˜¾å­˜ï¼‰")
    print("2. æ¨¡å‹æ–‡ä»¶æŸåæˆ–ä¸å®Œæ•´")
    print("3. transformersç‰ˆæœ¬è¿‡ä½ï¼ˆéœ€è¦>=4.37.0ï¼‰")
    print()
    print("å»ºè®®ï¼š")
    print("- å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–CPUæ¨¡å¼")
    print("- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ä¸‹è½½")
    sys.exit(1)

print()

# ==================== åˆ›å»ºå­¦ç”Ÿæ¨¡å‹ ====================
print("ğŸ“Œ åˆ›å»ºå­¦ç”Ÿæ¨¡å‹ï¼ˆå°æ¨¡å‹ï¼‰")
print("-" * 80)

try:
    student_model = torchvision.models.resnet18(pretrained=False, num_classes=10)
    student_model = student_model.to(DEVICE)

    student_params = sum(p.numel() for p in student_model.parameters()) / 1e6

    print(f"âœ… å­¦ç”Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ: ResNet18")
    print(f"   å‚æ•°é‡: {student_params:.2f}M")
    print(f"   å‹ç¼©æ¯”: {teacher_params * 1000 / student_params:.2f}x")
    print(f"   (ä» {teacher_params:.2f}B å‹ç¼©åˆ° {student_params:.2f}M)")

except Exception as e:
    print(f"âŒ å­¦ç”Ÿæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
    sys.exit(1)

print()

# ==================== è‡ªå®šä¹‰åˆ†ç±»å¤´ ====================
print("ğŸ“Œ ä¸ºQwen2.5-VLæ·»åŠ åˆ†ç±»å¤´")
print("-" * 80)

class QwenClassificationHead(nn.Module):
    """
    ä¸ºQwen2.5-VLæ·»åŠ ä¸€ä¸ªç®€å•çš„åˆ†ç±»å¤´
    å°†Qwençš„è¾“å‡ºæ˜ å°„åˆ°10ä¸ªç±»åˆ«çš„logits
    """
    def __init__(self, hidden_size=1536, num_classes=10):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, num_classes)
        )

    def forward(self, hidden_states):
        # å–æœ€åä¸€ä¸ªtokençš„hidden state
        if len(hidden_states.shape) == 3:
            hidden_states = hidden_states[:, -1, :]
        return self.classifier(hidden_states)

# åˆ›å»ºåˆ†ç±»å¤´
classification_head = QwenClassificationHead(
    hidden_size=teacher_model.config.hidden_size,
    num_classes=10
).to(DEVICE)

print(f"âœ… åˆ†ç±»å¤´åˆ›å»ºæˆåŠŸ")
print(f"   è¾“å…¥ç»´åº¦: {teacher_model.config.hidden_size}")
print(f"   è¾“å‡ºç±»åˆ«: 10")
print()

# ==================== Qwen2.5-VLå‰å‘ä¼ æ’­å‡½æ•° ====================
def get_teacher_logits(images, labels):
    """
    ä½¿ç”¨Qwen2.5-VLè·å–æ•™å¸ˆæ¨¡å‹çš„logits

    Args:
        images: (batch_size, 3, 224, 224)
        labels: (batch_size,)

    Returns:
        logits: (batch_size, num_classes)
    """
    batch_size = images.shape[0]

    # å°†tensorå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒï¼ˆQwenå¤„ç†å™¨éœ€è¦ï¼‰
    from PIL import Image
    import numpy as np

    pil_images = []
    for img in images:
        # åå½’ä¸€åŒ–
        img = img * 0.5 + 0.5  # [-1,1] -> [0,1]
        img = img.clamp(0, 1)
        img = (img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        pil_images.append(Image.fromarray(img))

    # æ„é€ è¾“å…¥ï¼ˆç®€å•çš„å›¾åƒåˆ†ç±»æç¤ºï¼‰
    messages_batch = []
    for pil_img in pil_images:
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": pil_img},
                    {"type": "text", "text": "Classify this image into one of these categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. Output only the category name."}
                ]
            }
        ]
        messages_batch.append(messages)

    # æ‰¹å¤„ç†
    all_logits = []

    with torch.no_grad():
        for messages in messages_batch:
            # å¤„ç†è¾“å…¥
            text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

            # è·å–å›¾åƒè¾“å…¥
            image_inputs = None
            for msg in messages:
                if isinstance(msg['content'], list):
                    for item in msg['content']:
                        if item.get('type') == 'image':
                            image_inputs = item['image']
                            break

            # ç¼–ç 
            inputs = processor(
                text=[text],
                images=[image_inputs] if image_inputs else None,
                return_tensors="pt"
            )

            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(teacher_model.device) for k, v in inputs.items()}

            # å‰å‘ä¼ æ’­
            outputs = teacher_model(**inputs, output_hidden_states=True)

            # ä»hidden statesæå–ç‰¹å¾
            hidden_states = outputs.hidden_states[-1]  # æœ€åä¸€å±‚

            # é€šè¿‡åˆ†ç±»å¤´
            logits = classification_head(hidden_states)

            all_logits.append(logits)

    # åˆå¹¶æ‰€æœ‰logits
    all_logits = torch.cat(all_logits, dim=0)

    return all_logits

print("âœ… Qwen2.5-VLæ¨ç†å‡½æ•°å·²å‡†å¤‡")
print()

# ==================== è’¸é¦æŸå¤± ====================
class DistillationLoss(nn.Module):
    def __init__(self, temperature=4.0, alpha=0.7):
        super().__init__()
        self.temperature = temperature
        self.alpha = alpha
        self.kl_div = nn.KLDivLoss(reduction='batchmean')
        self.ce_loss = nn.CrossEntropyLoss()

    def forward(self, student_logits, teacher_logits, labels):
        # è’¸é¦æŸå¤±
        student_soft = F.log_softmax(student_logits / self.temperature, dim=1)
        teacher_soft = F.softmax(teacher_logits / self.temperature, dim=1)
        distill_loss = self.kl_div(student_soft, teacher_soft) * (self.temperature ** 2)

        # å­¦ç”ŸæŸå¤±
        student_loss = self.ce_loss(student_logits, labels)

        # æ€»æŸå¤±
        total_loss = self.alpha * distill_loss + (1 - self.alpha) * student_loss

        return total_loss, distill_loss, student_loss

criterion = DistillationLoss(temperature=TEMPERATURE, alpha=ALPHA)
optimizer = optim.Adam(
    list(student_model.parameters()) + list(classification_head.parameters()),
    lr=LEARNING_RATE
)

print(f"ğŸ“Œ è’¸é¦æŸå¤±å‡½æ•°é…ç½®")
print("-" * 80)
print(f"âœ… æ¸©åº¦: {TEMPERATURE}, è’¸é¦æƒé‡: {ALPHA}")
print(f"âœ… ä¼˜åŒ–å™¨: Adam (å­¦ç”Ÿæ¨¡å‹ + åˆ†ç±»å¤´)")
print()

# ==================== è®­ç»ƒå‡½æ•° ====================
def train_one_epoch(epoch):
    student_model.train()
    classification_head.train()
    teacher_model.eval()

    running_total_loss = 0.0
    running_distill_loss = 0.0
    running_student_loss = 0.0
    correct = 0
    total = 0

    print(f"Epoch {epoch + 1}/{NUM_EPOCHS}")
    start_time = time.time()

    for batch_idx, (inputs, labels) in enumerate(trainloader):
        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

        # æ•™å¸ˆæ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆè·å–è½¯æ ‡ç­¾ï¼‰
        try:
            teacher_logits = get_teacher_logits(inputs, labels)
            teacher_logits = teacher_logits.to(DEVICE)
        except Exception as e:
            print(f"\nâš ï¸  Qwenæ¨ç†å¤±è´¥ (batch {batch_idx}): {e}")
            print("    è·³è¿‡æ­¤batch...")
            continue

        # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        student_logits = student_model(inputs)

        # è®¡ç®—è’¸é¦æŸå¤±
        total_loss, distill_loss, student_loss = criterion(
            student_logits, teacher_logits, labels
        )

        # åå‘ä¼ æ’­
        total_loss.backward()
        optimizer.step()

        # ç»Ÿè®¡
        running_total_loss += total_loss.item()
        running_distill_loss += distill_loss.item()
        running_student_loss += student_loss.item()

        _, predicted = student_logits.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        # æ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡
        if (batch_idx + 1) % 10 == 0:
            avg_total = running_total_loss / (batch_idx + 1)
            avg_distill = running_distill_loss / (batch_idx + 1)
            avg_student = running_student_loss / (batch_idx + 1)
            acc = 100.0 * correct / total

            print(f"  [{batch_idx + 1}/{len(trainloader)}] "
                  f"Total: {avg_total:.4f} | "
                  f"Distill: {avg_distill:.4f} | "
                  f"Student: {avg_student:.4f} | "
                  f"Acc: {acc:.2f}%")

            if DEVICE.type == 'cuda':
                print(f"     GPUæ˜¾å­˜: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")

    epoch_time = time.time() - start_time
    avg_total = running_total_loss / len(trainloader)
    avg_distill = running_distill_loss / len(trainloader)
    avg_student = running_student_loss / len(trainloader)
    acc = 100.0 * correct / total

    print(f"  Epochå®Œæˆ! ç”¨æ—¶: {epoch_time:.2f}s")
    print(f"  æ€»æŸå¤±: {avg_total:.4f} | è’¸é¦æŸå¤±: {avg_distill:.4f} | "
          f"å­¦ç”ŸæŸå¤±: {avg_student:.4f} | å‡†ç¡®ç‡: {acc:.2f}%")

    return avg_total, acc

# ==================== æµ‹è¯•å‡½æ•° ====================
def test():
    student_model.eval()
    test_loss = 0
    correct = 0
    total = 0

    ce_loss = nn.CrossEntropyLoss()

    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            outputs = student_model(inputs)
            loss = ce_loss(outputs, labels)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    avg_loss = test_loss / len(testloader)
    acc = 100.0 * correct / total

    print(f"  æµ‹è¯•é›†ç»“æœ: Loss: {avg_loss:.4f} | Acc: {acc:.2f}% ({correct}/{total})")

    return avg_loss, acc

# ==================== å¼€å§‹è®­ç»ƒ ====================
print("=" * 80)
print("ğŸ‹ï¸  å¼€å§‹Qwen2.5-VLçŸ¥è¯†è’¸é¦è®­ç»ƒ")
print("=" * 80)
print()

training_start = time.time()
best_acc = 0.0

try:
    for epoch in range(NUM_EPOCHS):
        train_loss, train_acc = train_one_epoch(epoch)

        print(f"  æ­£åœ¨æµ‹è¯•...")
        test_loss, test_acc = test()

        if test_acc > best_acc:
            best_acc = test_acc
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")

        print()

    total_time = time.time() - training_start
    print("=" * 80)
    print(f"âœ… Qwen2.5-VLè’¸é¦è®­ç»ƒå®Œæˆ! æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
    print(f"   æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.2f}%")
    print("=" * 80)

except KeyboardInterrupt:
    print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
except Exception as e:
    print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
    import traceback
    traceback.print_exc()

print()

# ==================== ä¿å­˜æ¨¡å‹ ====================
print("ğŸ“Œ ä¿å­˜æ¨¡å‹")
print("-" * 80)

model_save_dir = Path("./test_models")
model_save_dir.mkdir(exist_ok=True)

try:
    student_path = model_save_dir / "student_resnet18_qwen_distilled.pth"
    torch.save({
        'epoch': NUM_EPOCHS,
        'student_state_dict': student_model.state_dict(),
        'classification_head_state_dict': classification_head.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'best_acc': best_acc,
        'temperature': TEMPERATURE,
        'alpha': ALPHA,
    }, student_path)

    print(f"âœ… å­¦ç”Ÿæ¨¡å‹å·²ä¿å­˜: {student_path}")
    print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")

except Exception as e:
    print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

print()

# ==================== æ€»ç»“ ====================
print("=" * 80)
print("ğŸ“Š Qwen2.5-VLçŸ¥è¯†è’¸é¦æ€»ç»“")
print("=" * 80)
print()

print("âœ… å®Œæˆçš„ä»»åŠ¡:")
print("   - åŠ è½½Qwen2.5-VL-3B-Instructå¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰")
print("   - åˆ›å»ºResNet18å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰")
print("   - ä»å¤§æ¨¡å‹æå–è½¯æ ‡ç­¾")
print("   - å®Œæ•´è’¸é¦è®­ç»ƒæµç¨‹")
print("   - æ¨¡å‹ä¿å­˜")
print()

print("ğŸ“ æ¨¡å‹å¯¹æ¯”:")
print(f"   æ•™å¸ˆæ¨¡å‹: Qwen2.5-VL-3B-Instruct ({teacher_params:.2f}Bå‚æ•°)")
print(f"   å­¦ç”Ÿæ¨¡å‹: ResNet18 ({student_params:.2f}Må‚æ•°)")
print(f"   å‹ç¼©æ¯”: {teacher_params * 1000 / student_params:.0f}x")
print()

if DEVICE.type == 'cuda':
    print("ğŸ’¡ èµ„æºä½¿ç”¨:")
    print(f"   æœ€å¤§æ˜¾å­˜: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB")
    print(f"   å½“å‰æ˜¾å­˜: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
print()

print("ğŸš€ è¿™è¯æ˜äº†:")
print("   âœ… å¯ä»¥ä½¿ç”¨Qwen2.5-VLè¿™æ ·çš„è¶…å¤§å¤šæ¨¡æ€æ¨¡å‹ä½œä¸ºæ•™å¸ˆ")
print("   âœ… å¯ä»¥å°†çŸ¥è¯†æˆåŠŸè’¸é¦åˆ°å°æ¨¡å‹ï¼ˆResNet18ï¼‰")
print("   âœ… å®ç°äº†273å€çš„æ¨¡å‹å‹ç¼©")
print("   âœ… è’¸é¦åçš„å°æ¨¡å‹å¯ä»¥ç‹¬ç«‹éƒ¨ç½²ä½¿ç”¨")
print()

print("ğŸ“ çœŸå®åº”ç”¨å»ºè®®:")
print("   1. ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†ï¼ˆImageNet, COCOç­‰ï¼‰")
print("   2. å¢åŠ è®­ç»ƒè½®æ•°ï¼ˆ50-200 epochsï¼‰")
print("   3. ä½¿ç”¨Qwen2.5-VLçš„å›¾åƒç†è§£èƒ½åŠ›æå–æ›´ä¸°å¯Œçš„ç‰¹å¾")
print("   4. å¯ä»¥è’¸é¦åˆ°å¤šä¸ªä¸åŒæ¶æ„çš„å°æ¨¡å‹")
print("   5. å¯ä»¥æ·»åŠ ä¸­é—´å±‚ç‰¹å¾è’¸é¦")
print()

print("=" * 80)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 80)
